# 分库分表总结

# 1.分库分表概念

**分表**:就是把一个表的数据放到多个表中,然后查询的时候就查一个表.这样可以控制每个表的数据量在可控的范围内,比如每个表就固定在200W以内;

**分库**:一个库一般经验而言,最多支撑到并发2000,一定要扩容了,而且一个健康的单库并发值最好保持在每秒1000左右,不要太大.那么可以将一个库的数据拆分到多个库中,访问的时候就访问一个库;

## 1.1.中间件

**sharding-jdbc**:当当开源的,属于client层方案.确实之前用的比较多一些,因为SQL语法支持也比较多,没有太多限制,而且目前推出到了2.0版本,支持分库分表,读写分离,分布式id生成,柔性事务(最大努力送达型事务,TCC事务).而且确实之前使用的公司会比较多一些,目前社区还一直在开发和维护,也算是比较活跃;

**mycat**:基于cobar改造,属于proxy层方案,支持的功能非常完善,而且目前应该也是非常火的而且不断流行的数据库中间件,社区很活跃,也有一些公司开始在用了.但是确实相比于sharding jdbc来说,年轻一些,经历的锤炼少一些;

![image-20210725105815232](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210725105815232.png)

## 1.2.数据库如何拆分

* 水平拆分的意思就是把一个表的数据放到多个库的多个表里,但是每个库的表结构都是一样的,只不过每个库表放的数据是不同的,所有库表的数据  加起来就是全部数据;水平拆分的意义,就是将数据均匀放更多的库里,然后用多个库来抗更高的并发,还有就是用多个库的存储容量来进行扩容;
* 垂直拆分的意思就是把一个有很多字段的表给拆分成多个表,或者是多个库上去.每个库表的结构都不一样,每个库表都包含部分字段.一般来说,会将较少的访问频率很高的字段放到一个表里去,然后将较多的访问频率很低的字段放到另一个表里去.因为数据库是有缓存的,访问频率高的行字段越少,就可以在缓存里缓存更多的行.性能就越好.(如拆分:订单表,订单支付表,订单详情表);

下图是基于使用水平拆分的分库分表

![image-20210725112440928](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210725112440928.png)

# 2.单库单表迁移分库分表

## 2.1.长时间停机分库分表

![image-20210725115715990](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210725115715990.png)

## 2.2.不停机双写方案

![image-20210725115928734](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210725115928734.png)

# 3.动态扩容缩容的分库分表方案

  ![image-20210725141646827](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210725141646827.png)

这种动态扩容缩容的方案类似于Redis Cluster集群的扩容缩容的方案;

# 4.分库分表之后的全局Id的生成

雪花算法

# 5.读写分离

## 5.1.为什么要读写分离?

![image-20200531201731840](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200531201731840.png)

## 5.2.MySQL主从复制的原理是什么?

![image-20200531203245959](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200531203245959.png)

主库将变更写binlog日志,然后从库连接到主库之后,从库有一个IO线程,将主库的binlog日志拷贝到自己本地,写入一个中继日志中.接着从库中有一个SQL线程会从中继日志读取binlog,然后执行binlog日志中的内容,也就是在自己本地再执行一遍SQL,这样就可以保证自己跟主库的数据是一样的.

这里有一个非常重要的一点,就是从库同步主库数据的过程是串行化的,也就是说主库上并行的操作,在从库上会串行执行,所以这就是一个非常重要的点了,由于从库从主库拷贝日志以及串行执行SQL的特点,在高并发场景下,从库的数据一定会比主库慢一些,是由延时的.所以经常出现,刚写入主库的数据可能是读不到的,要过几十毫秒,甚至几百毫秒才能读取到;

而且这里还有另一个问题,就是如果主库突然宕机,然后恰好数据还没同步到从库,那么有些数据可能在从库上是没有的,有些数据可能就丢失了;

所以MySQL实际上在这里有两个机制,一个是**半同步复制**,用来解决主库数据丢失问题,一个是**并行复制**,用来解决主从同步延迟问题;

* **半同步复制(semi-sync)**,指的就是主库写入binlog日志之后,就会将强制此时立即将数据同步到从库,从库将日志写入自己本地的relay log之后,接着会返回一个ack给主库,主库接收到至少一个从库的ack之后才会认为写操作完成了;
* **并行复制**,指的是从库开启多个线程,并行读取relay log中不同库的日志,然后并行重放不同库的日志,这是库级别的并行;

如果主从延迟比较严重:

1. 分库,将一个主库拆分为4个主库,每个主库的写并发就会降低,此时主从延迟就可以忽略不计;
2. 打开MySQL支持的并行复制,多个库并行复制;
3. 重写代码,需要慎重,插入数据之后,直接就更新不要查询;
4. 如果确实是存在必须先插入,立马要求就查询到,对这个查询设置直连主库.不推荐这种做法;

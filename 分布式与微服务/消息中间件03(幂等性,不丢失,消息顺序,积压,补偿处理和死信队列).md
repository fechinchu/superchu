# 消息中间件03-幂等性,不丢失,消息顺序,积压,补偿处理和死信队列

# 1.如何保证消息消费时的幂等性

kafka出现重复消息的原因?

<img src="https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200520175631593.png" alt="image-20200520175631593" style="zoom:33%;" />

如何解决重复消费的问题?

<img src="https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200520192131659.png" alt="image-20200520192131659" style="zoom:33%;" />

我们往Redis中插入数据`setnx`,如果插入成功,那就消费;如果插入失败,那就不消费;

# 2.如何保证消息不会丢失

<img src="https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200520194847065.png" alt="image-20200520194847065" style="zoom:33%;" />

## 2.1.生产者弄丢数据

生产者将数据发送到rabbitmq的时候,可能数据在半路就弄丢了.

此时可以选择用rabbitmq提供的**事务功能**,就是生产者发送数据之前开启rabbitmq事务(channel.txSelect),然后发送消息,如果消息没有成功被RabbitMQ接收到,那么生产者会收到异常报错,此时就可以回滚事务(channel.txRollback),然后重试发送消息;如果收到了消息,那么可以提交事务(channel.txCommit).但是问题是,rabbitmq事务机制会让吞吐量下来,因为太耗性能;

也可以开启**confirm模式**,在生产者设置开启confirm模式,之后每写的消息都会分配一个唯一的id,如果写入了rabbitmq中,rabbitmq会回传一个ack消息,告诉你说这个消息OK了.如果rabbitmq没有处理这个消息,会回调一个nack接口,告诉你这个消息接收失败,可以重试.而且可以结合这个机子自己在内存里维护每个消息id的状态,如果超过一定时间还没接收到这个消息的回调,那么可以重发;

事务和confirm机制的最大不同在于,事务机制是同步的,你提交一个事务之后会阻塞在那儿,但是confirm机制是异步的,发送一个消息之后就可以发送下一个消息,然后那个消息rabbitmq接收了之后会异步回调你的一个接口通知你这个消息接收到了;

> 在 rabbitmq 中我们可以通过持久化数据解决 rabbitmq 服务器异常的数据丢失问题。
>
> 问题：生产者将消息发送出去之后，消息到底有没有到达 rabbitmq 服务器。默认情况下是不知道的。
>
> 两种方式：
>
> - AMQP 实现了事务机制
> - Confirm 模式
>
> #### 事务机制
>
> - txSelect：用户将当前的 channel 设置成 transaction 模式
> - txCommit：用于提交事务
> - txRollback：回滚事务
>
> 缺点：降低了 rabbitmq 的吞吐量。
>
> **生产者**
>
> ```java
> public class TxSend {
>     private static final String QUEUE_NAME = "test_queue_tx";
>     public static void main(String[] args) throws IOException, TimeoutException {
>         Connection connection = ConnectionUtils.getConnection();
>         Channel channel = connection.createChannel();
>         channel.queueDeclare(QUEUE_NAME, false, false, false, null);
> 
>         String msg = "hello tx message!";
> 
>         try {
>             channel.txSelect();
>             channel.basicPublish("", QUEUE_NAME, null, msg.getBytes());
>             // 出错测试
>             int xx = 1 / 0;
>             System.out.println("send: " + msg);
>             channel.txCommit();
>         } catch (Exception e) {
>             channel.txRollback();
>             System.out.println("send message rollback.");
>         }
> 
>         channel.close();
>         connection.close();
>     }
> }
> ```
>
> **消费者**
>
> ```java
> public class TxRecv {
>     private static final String QUEUE_NAME = "test_queue_tx";
>     public static void main(String[] args) throws IOException, TimeoutException {
>         Connection connection = ConnectionUtils.getConnection();
>         Channel channel = connection.createChannel();
>         channel.queueDeclare(QUEUE_NAME, false, false, false, null);
> 
>         channel.basicConsume(QUEUE_NAME, true, new DefaultConsumer(channel){
>             @Override
>             public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
>                 System.out.println("recv[tx] msg: " + new String(body, "utf-8"));
>             }
>         });
>     }
> }
> ```
>
> #### Confirm 模式
>
> **生产者端 confirm 模式的实现原理**
>
> 生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式，所有在该信道上面发布的消息都会被指派一个唯一的 ID(从1开始)，一旦消息被投递到所有的匹配队列之后，broker 就会发送一个确认给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker 回传给生产者的确认消息中 deliver-tag 域包含了确认消息的序列号，此外 broker 也可以设置 basic.ack 的 multiple 域，表示这个序列号之前的所有消息已经得到了处理。
>
> confirm 模式最大的好处在于它是异步的。
>
> 开启 confirm 模式：
>
> ```java
> channel.confirmSelect();
> ```
>
> 编程模式：
>
> - 普通 发一条 waitForConfirms()
> - 批量 发一批 waitForConfirms()
> - 异步 confirm 模式：提供一个回调方法
>
> **confirm 单条**
>
> ```java
> public class Send1 {
>     private static final String QUEUE_NAME = "test_queue_confirm1";
>     public static void main(String[] args) throws IOException, TimeoutException, InterruptedException {
>         Connection connection = ConnectionUtils.getConnection();
>         Channel channel = connection.createChannel();
>         channel.queueDeclare(QUEUE_NAME, false, false, false, null);
> 
>         // 生产者调用 confirmSelect 将 channel 设置成为 confirm 模式 （注意）
>         channel.confirmSelect();
>         String msg = "hello confirm message!";
>         channel.basicPublish("", QUEUE_NAME, null, msg.getBytes());
>         if (!channel.waitForConfirms()) {
>             System.out.println("message send failed.");
>         } else {
>             System.out.println("message send ok.");
>         }
>         channel.close();
>         connection.close();
>     }
> }
> ```
>
> **confirm 批量**
>
> ```java
> public class Send2 {
>     private static final String QUEUE_NAME = "test_queue_confirm1";
>     public static void main(String[] args) throws IOException, TimeoutException, InterruptedException {
>         Connection connection = ConnectionUtils.getConnection();
>         Channel channel = connection.createChannel();
>         channel.queueDeclare(QUEUE_NAME, false, false, false, null);
> 
>         // 生产者调用 confirmSelect 将 channel 设置成为 confirm 模式 （注意）
>         channel.confirmSelect();
> 
>         String msg = "hello confirm message batch!";
>         // 批量模式
>         for (int i = 0; i< 10; i++) {
>             channel.basicPublish("", QUEUE_NAME, null, msg.getBytes());
>         }
>         // 确认
>         if (!channel.waitForConfirms()) {
>             System.out.println("message send failed.");
>         } else {
>             System.out.println("message send ok.");
>         }
>         channel.close();
>         connection.close();
>     }
> }
> ```
>
> **confirm 异步**
>
> Channel 对象提供的 ConfirmListener() 回调方法只包含 deliveryTag (当前 Channel 发出的消息序号)，我们需要自己为每一个 Channel 维护一个 unconfirm 的消息序号集合，每 publish 一条数据，集合中元素加 1，每回调一次 handleAck 方法，unconfirm 集合删掉相应的一条(multiple=false)或多条(multiple=true)记录。从程序运行效率上看，这个 unconfirm 集合最好采用有序集合 SortedSet 存储结构。
>
> ```java
> public class Send3 {
>     private static final String QUEUE_NAME = "test_queue_confirm3";
>     public static void main(String[] args) throws IOException, TimeoutException {
>         Connection connection = ConnectionUtils.getConnection();
>         Channel channel = connection.createChannel();
>         channel.queueDeclare(QUEUE_NAME, false, false, false, null);
> 
>         // 生产者调用 confirmSelect 将 channel 设置为 confirm 模式
>         channel.confirmSelect();
> 
>         // 未确认的消息标识
>         final SortedSet<Long> confirmSet = Collections.synchronizedSortedSet(new TreeSet<Long>());
> 
>         // 通道添加监听
>         channel.addConfirmListener(new ConfirmListener() {
>             // 没有问题的 handleAck
>             public void handleAck(long l, boolean b) throws IOException {
>                 if (b) {
>                     System.out.println("---handleAck---multiple");
>                     confirmSet.headSet(l + 1).clear();
>                 } else {
>                     System.out.println("---handleAck---multiple false");
>                     confirmSet.remove(l);
>                 }
>             }
>             // handleNack 1s 3s 10s xxx...
>             public void handleNack(long l, boolean b) throws IOException {
>                 if (b) {
>                     System.out.println("---handleNack---multiple");
>                     confirmSet.headSet(l + 1).clear();
>                 } else {
>                     System.out.println("---handleNack---multiple false");
>                     confirmSet.remove(l);
>                 }
>             }
>         });
> 
>         String msg = "sssss";
>         while (true) {
>             long seqNo = channel.getNextPublishSeqNo();
>             channel.basicPublish("", QUEUE_NAME, null, msg.getBytes());
>             confirmSet.add(seqNo);
>         }
>     }
> }
> ```
>
> **消费者**
>
> (只需修改 QUEUE_NAME)

## 2.2.rabbitmq弄丢数据

你必须开启rabbitmq的持久化,就是消息写入之后会持久化到磁盘,哪怕是rabbitmq自己挂了,恢复之后会自动读取之前存储的数据,一般数据不会丢.除非极其其罕见的是rabbitmq还没有持久化,自己就挂了,可能导致少量数据会丢失,但是这个概率很小.

设置持久化有两个步骤,第一个是创建queue的时候将其设置为持久化,这样就可以保证rabbitmq持久化queue的元数据,但是不会持久化queue里的数据;第二个是发送消息的时候将消息的deliveryMode设置为2,就是将消息设置为持久化的,此时rabbitmq就会将消息持久化到磁盘上去,必须要同时设置这两个持久化才行,rabbitmq哪怕是挂了,再次重启,也会从磁盘上重启恢复queue,恢复queue里的数据;

## 2.3.消费者弄丢数据

这个时候需要用rabbitmq提供的ack机制;简单来说就是需要我们关闭rabbitmq自动ack,每次自己代码里确保处理完的时候,在程序里ack一把.这样的话,如果你还没处理完,没有ack.那么rabbitmq就会认为你还没处理完,这个时候rabbitmq会把这个消费分配给别的consumer区处理;

# 3.如何保证消息的顺序

![image-20200520215103085](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200520215103085.png)

* 保证消息发送时候有序同步发送;
* 保证消息发送被同一队列接收;
* 保证一个队列只有一个消费者,可以有从机(待机状态),实现高可用;

# 4.消息积压如何处理

* 事前:
  * 首先消息重回队列的话这个要设置成false,防止一个消息一直在死循环导致后续消息无法消息,最终导致消息积压;
  * 设置死信队列和TTL过期时间,假如超出队列长度,超过过期时间直接转到死信队列;
* 事后:
  * 先修复consumer的问题,确保其回复消费速度.增加消费者的数量;

# 5.MQ补偿方案

## 5.1.方案一

如下的补偿会对数据库有两次入库,一次业务数据入库,一次消息入库.对数据库来说是个瓶颈;

![image-20210708113939314](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210708113939314.png)

## 5.2.方案二

![image-20210708114015259](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210708114015259.png)

1. 业务消息入库成功后,第一次消息发送;
2. 同样在消息入库成功后,发送第二次消息,这两条消息是同时发送的.第二条消息是延迟检查,可以设置2min,5min延迟发送;
3. 消费端监听指定队列;
4. 消费端处理完消息后,内部生成新的消息send confirm,投递到MQ Broker;
5. Callback Service回调服务监听MQ Broker,如果受到Downstream service发送的消息,则可以确定消息发送成功,执行消息存储到MSG DB;s
6. Check Detail检查监听step2延迟投递的消息,此时监听的队列不是同一个,5分钟后,Callback service受到消息,检查MSG DB.如果发现之前的消息已经投递成功,则不需要做其他事情.如果检查发现失败,则Callback进行补偿,主动发送RPC通信,通知上游生产端重新发送消息.

# 6.重回队列和死循环

消费端进行消费的时候,如果由于业务异常可以进行日志记录进行补偿;如果由于服务器宕机等严重问题,就需要手工进行ACK保障消费端消费成功.

消费端重回队列是为了对没有处理成功的消息,把消息重新传给Broker.一般在实际应用中,都会关闭重回队列,也就是设置为False;

生产者:

~~~java
public class Producer {

    public static void main(String[] args) throws Exception {
        
        //1创建ConnectionFactory
        Connection connection = ConnectionUtils.getConnection();
        Channel channel = connection.createChannel();
        
        String exchange = "test_ack_exchange";
        String routingKey = "ack.save";
        for(int i =0; i<5; i ++){
            
            Map<String, Object> headers = new HashMap<String, Object>();
            headers.put("num", i);
            
            //添加属性，后续会使用到
            AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
                    .deliveryMode(2) //投递模式，持久化
                    .contentEncoding("UTF-8")
                    .headers(headers)
                    .build();
            String msg = "Hello RabbitMQ ACK Message " + i;
            channel.basicPublish(exchange, routingKey, true, properties, msg.getBytes());
        }
    }
}
~~~

消费者:

~~~java
public class Consumer {
    public static void main(String[] args) throws Exception {
        //1创建ConnectionFactory
        Connection connection = ConnectionUtils.getConnection();
        Channel channel = connection.createChannel();   
        String exchangeName = "test_ack_exchange";
        String queueName = "test_ack_queue";
        String routingKey = "ack.#";
        
        channel.exchangeDeclare(exchangeName, "topic", true, false, null);
        channel.queueDeclare(queueName, true, false, false, null);
        channel.queueBind(queueName, exchangeName, routingKey);
        
        // 手工签收 必须要关闭 autoAck = false
        channel.basicConsume(queueName, false, new MyConsumer(channel));       
    }
}


public class MyConsumer extends DefaultConsumer {

    private Channel channel ;
    
    public MyConsumer(Channel channel) {
        super(channel);
        this.channel = channel;
    }

    @Override
    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
        System.err.println("-----------consume message----------");
        System.err.println("body: " + new String(body));
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        if((Integer)properties.getHeaders().get("num") == 0) {
            //Nack三个参数  第二个参数：是否是批量，第三个参数：是否重回队列（需要注意可能会发生重复消费，造成死循环）
            channel.basicNack(envelope.getDeliveryTag(), false, true);
        } else {
            channel.basicAck(envelope.getDeliveryTag(), false);
        }
    }
}
~~~

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210708134639407.png" alt="image-20210708134639407" style="zoom: 33%;" />

这种情况就会出现死循环,我们可以设置重试次数;

# 7.死信队列

死信队列:DLX,Dead-Letter-Exchange.RabbitMQ的死信队列里与Exchange息息相关;

利用DLX,当消息在一个队列中变成死信(dead message)之后,它能被重新publish到另一个Exchange,这个Exchange就是DLX.

消息编程死信有以下几种情况:

* 消息被拒绝(basic.reject/basic.nack)并且requeue = false;
* 消息TTL过期;
* 队列达到最大长度;

DLX也是一个正常的Exchange,和一般的Exchange没有区别,它能在任何的队列上被指定,是加上就是设置某个队列的属性.当这队列中有死信时候,RabbitMQ就会自动的将这个消息重新发布到设置的Exchange上去,进而被路由到另一个队列.可以监听这个队列中的消息做相应的处理.

创建交换机和队列以及绑定:

~~~java
 /**
 * 死信交换机
 */
@Bean
public DirectExchange dlxExchange(){
	return new DirectExchange(dlxExchangeName);
}

/**
 * 死信队列
 */
@Bean
public Queue dlxQueue(){
	return new Queue(dlxQueueName);
}

/**
 * 死信队列绑定死信交换机
 */
@Bean
public Binding dlcBinding(Queue dlxQueue, DirectExchange dlxExchange){
	return BindingBuilder.bind(dlxQueue).to(dlxExchange).with(dlxRoutingKey);
}

/**
 * 业务队列
 */
@Bean
public Queue queue(){
	Map<String,Object> params = new HashMap<>();
	params.put("x-dead-letter-exchange",dlxExchangeName);//声明当前队列绑定的死信交换机
	params.put("x-dead-letter-routing-key",dlxRoutingKey);//声明当前队列的死信路由键
	params.put("x-message-ttl",10000);//设置队列消息的超时时间，单位毫秒，超过时间进入死信队列
	params.put("x-max-length", 10);//生命队列的最大长度，超过长度的消息进入死信队列
	return QueueBuilder.durable(queueName).withArguments(params).build();
}

/**
 * 业务交换机
 */
@Bean
public FanoutExchange fanoutExchange(){
	return new FanoutExchange(exchangeName,true,false);
}

/**
 * 业务队列和业务交换机的绑定
 */
@Bean
public Binding binding(Queue queue, FanoutExchange fanoutExchange){
	return  BindingBuilder.bind(queue).to(fanoutExchange);
}
~~~

~~~yaml
spring:
  rabbitmq:
    addresses: 127.0.0.1:5672
    username: lzm
    password: lzm
    virtual-host: test
    listener:
      simple:
        acknowledge-mode: manual  # 手动ack
        default-requeue-rejected: false # 设置为false，requeue或reject
~~~

创建业务队列的部分,设置业务队列的超时时间是10S,队列中最大的消息为10.上面的代码中,业务交换机为fanout类型的交换机,死信交换机为Direct类型的交换机.

生产者代码如下:

~~~java
public void send(){
	for (int i = 0; i < 5; i++) {
		CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());
		rabbitTemplate.convertAndSend(exchangeName,"","消息==>"+i,message -> {
			message.getMessageProperties().setExpiration(3000+"");//发送消息时设置消息的超时时间
			return message;
		},correlationData);
	}
}
~~~

队列中的消息的超时时间可以是在创建队列时设置,表示对队列中所有的消息生效,也可以在发送消息时设置,两者相比取最小值作为TTL的值.

![image-20210708145103294](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210708145103294.png)

当消费在队列中的时间超过TTL的时候时,消息会自动进入死信队列.针对这一特性,**可以给消息设置过期时间后发送到某个队列,从而来进行延迟消费*.

上述红框内容:

* Lim:表示设置了队列中消息数量`x-max-length`参数;
* DLX:表示设置了死信交换机`x-dead-letter-exchange`参数;
* DLK:表示设置了死信路由键`x-dead-letter-routing-key`参数,不设置该值时,消息在进入死信队列后,路由键保持原来的不变,设置了该值,消息的路由键就变为了新设置的值;

~~~java
@RabbitHandler
@RabbitListener(queues = {"${platform.queue-name}"},concurrency = "1")
public void msgConsumer(String msg, Channel channel, Message message) throws IOException {
	try {
		if(msg.indexOf("5")>-1){
			throw new RuntimeException("抛出异常");
		}
		log.info("消息{}消费成功",msg);
		channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
	} catch (Exception e) {
		log.error("接收消息过程中出现异常，执行nack");
		//第三个参数为true表示异常消息重新返回队列，会导致一直在刷新消息，且返回的消息处于队列头部，影响后续消息的处理
		channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, false);
		log.error("消息{}异常",message.getMessageProperties().getHeaders());
	}
}
~~~

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210708150341042.png" alt="image-20210708150341042" style="zoom:50%;" />

查看死信队列中的数据:

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210708150414598.png" alt="image-20210708150414598" style="zoom: 33%;" />


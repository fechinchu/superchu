# 2.MySQL-实战1

## 1.普通索引和唯一索引的区别

### 1.1.查询过程的区别

![image-20210411192311560](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210411192311560.png)

假设,执行查询的语句是`select id from T where k = 5`.这个查询语句在索引树上查找的过程,先是通过B+树从树跟开始,按层搜索到叶子节点.

* 对于普通索引来说,查找到满足条件的第一个记录(5,500)后,需要查找下一个记录,直到碰到第一个不满足k=5条件的记录;
* 对于唯一索引来说,由于索引定义了唯一性,查找到第一个满足条件的记录后,就会停止继续检索;

InnoDB的数据是按数据页为单位来读写的.也就是说,当需要读一条记录的时候,并不是将这个记录本身从磁盘读出来,而是以页为单位,将其整体读入内存.在InnoDB中,每个数据页的大小默认是16KB.

### 1.2.更新过程的区别

#### 1.2.1.change buffer

当需要更新一个数据页时,如果数据页在内存中就直接更新,而如果这个数据页还没有在内存中的话,在不影响数据一致性的前提下,InnoDB会将这些操作缓存在change buffer中,这样就不需要从磁盘中读取这个数据页了.在下次查询需要访问这个数据页的时候,将数据页读入内存,然后执行change buffer中与页有关的操作.虽然名字叫change buffer,实际上它是可以持久化的数据,也就是说,change buffer在内存中有拷贝,也会被写入到磁盘上.

将change buffer中的操作应用到原数据页,得到最新结果的过程称为merge.除了访问这个数据页会触发merge外,系统有后台线程也会定期merge.数据库正常关闭(shutdown)的过程中,也会执行merge操作.

#### 1.2.2.区别

对于唯一索引来说.所有的更新操作都要先判断这个操作是否违反唯一性约.比如,要插入(4,400)这个记录,就要先判断现在表中是否存在k=4的记录,而这必须要将数据页读入到内存才能判断.如果都已经读入到内存了,那直接更新内存会更快,就没必要使用change buffer了.因此,唯一索引的更新就不能使用change buffer,实际上也只有普通索引可以使用.

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 `innodb_change_buffer_max_size` 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%

> 在表中插入一个新记录(4,400)的话,InnoDB的处理流程:
>
> * 这个记录要更新在目标页在内存中.
>   * 对于唯一索引来说,找到3和5之间的位置,判断到没有冲突,插入这个值,语句执行结束;
>   * 对于普通索引来说,找到3和5之间的位置,插入这个值,语句执行结束;
> * 这个记录要更新的目标页不在内存中.
>   * 对于唯一索引,需要将数据页读入到内存,判断到没有冲突,插入这个值,语句执行结束;
>   * 对于普通索引来说,则是将更新记录在change buffer,语句执行就结束了.

### 1.3.change buffer和redo log

假设我们要在表上执行插入语句

~~~mysql
mysql> insert into t(id,k) values(id1,k1),(id2,k2);
~~~

假设当前k索引树的状态,查找到位置后,k1所在的数据页在内存(InnoDB buffer pool)中,k2所在的数据页不在内存中.

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210412094240325.png" alt="image-20210412094240325" style="zoom:50%;" />

分析上图,涉及四个部分:内存,redo_log(ib_log_fileX),数据表空间(t.ibd),系统表空间(ibdata1);

数据表空间:就是一个个的表数据文件,对应的磁盘文件就是"表名.ibd";系统表空间:用来放系统信息,数据字典等.对应的磁盘文件是"ibdata1";

这条更新语句做的操作如下:

1. Page1 在内存中,直接更新内存;
2. Page2 没有在内存中,就在内存的change buffer区域,记录下"我要往Page2插入一行"这个信息;
3. 将上述两个动作记录redo log;

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210412101559574.png" alt="image-20210412101559574" style="zoom:50%;" />

如果读语句发生在更新语句后不久,内存中的数据都还在:

1. 读Page1的时候,直接从内存返回.
2. 读Page2的时候,需要把Page2从磁盘读入内存中,然后应用到change buffer里面的操作日志,生成一个正确的版本并返回;可以看到,直到需要读Page2的时候,这个数据页才会被读入内存;

总结的话:**redo log主要节省的是随机写磁盘的IO消耗(转换成顺序写),而change buffer主要节省的是随机读磁盘的IO消耗**;

## 2.MySQL为什么会选错索引

### 2.1.优化器的逻辑

优化器选择索引的目的,是找到一个最优的执行方案,并用最小的代价去执行语句.在数据库里面,扫描行数是影响执行代价的因素之一.扫描行数越少,以为这访问磁盘数据的次数越少,消耗的CPU资源越少;扫描的行数并不是唯一的判断标准,优化器还会结合是否使用临时表,是否排序等因素进行综合判断.

 ### 2.2.扫描行数如何判断?

MySQL在真正开始执行语句之前,并不能精确地知道满足这个条件的记录有多少条,而只能根据统计信息来估算记录数.这个统计信息就是索引的区分度.一个索引上不同的值越多,这个索引的区分度就越好.而一个索引上不同的值个数,我们称之为"基数"(cardinality).也就是说,这个基数越大,索引区分度越好.我们可以使用`show index`方法,看到一个索引的基数.

MySQL在获取索引基数的时候并不会把整张表取出来一行行统计,虽然可以得到精确的结果,但是代价太高,所以只能选择"采样统计".采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。

在MySQL中,有两种存储索引统计的方式,可以通过设置参数`innodb_stats_persisent`的值来选择:

* 设置为on的时候,表示统计信息会持久化存储,这时,默认的N是20,M是10;
* 设置为off的时候,表示统计信息只存储在内存中.这时,默认6;的N是8,M是16;

如果是统计信息不对,我们可以使用`analyze table T`命令,重新来统计索引信息.

### 2.3.索引选择异常和处理

* 采用force index强制选择一个索引;
* 修改SQL语句,引导MySQL使用我们期望的索引;
* 可以新建一个更合适的索引,来提供给优化器做选择,或删除误用的索引;

## 3.如何给字符串字段加索引

不是很重要

## 4.SQL语句为什么会间接性变慢?

### 4.1.问题出现原因

当内存数据页跟磁盘数据页内容不一致的时候,我们称这个内存页为"脏页".内存数据写入到磁盘后,内存和裁判上的数据页的内容也就一致了,称为干净页;

平时执行很快的更新操作,其实就是在写内存和日志,而MySQL偶尔间接性变慢,可能就是在刷脏页.

* 场景一:对应的就是InnoDB的redo log写满了.这时候系统会停止所有的更新操作,把checkpoint往前推进,redo log留出空间;
* 场景二:当系统内存不足,当需要新的内存页,而内存不够用的时候,就需要淘汰一些数据页,空出内存给别的数据页使用.如果淘汰的是"脏页"写到磁盘;
* 场景三:MySQL认为系统空闲的时候刷脏页;
* 场景四:MySQL正常关闭的情况下.这时候,MySQL会把内存的脏页都flush到磁盘上.下次MySQL启动的时候,就可以从磁盘上读取数据,启动速度会很快;

第一种是"redo log写满了,要flush脏页",这种情况是InnoDB要尽量避免的,如果出现这种情况的时候,整个系统就不能再接收更新了,所有的更新都必须堵住.

第二种是"内存不够用了,要将脏页写到磁盘",这种情况其实是常态,InnoDB用缓冲池(buffer pool)管理内存,缓冲池中的内存页有三种状态:

* 第一种是,还没有使用的;
* 第二种是,使用了并且是干净页;
* 第三种是,使用了并且是脏页;

当要读入的数据页没有在内存的时候,就必须到缓冲池中申请一个数据页.这时候只能把最久不使用的数据页从内存中淘汰掉.如果要淘汰的是一个干净页,就直接释放出来复用,但如果是脏页,就必须将脏页先刷到磁盘,变成干净页后才能复用.

### 4.2.InnoDB刷脏页的控制策略

我们需要正确的设置InnoDB所在主机的IO能力,这样InnoDB才能知道要全力刷脏页的时候,可以刷多块.

这需要设置innodb_io_capacity这个参数,它会让InnoDB了解磁盘能力.建议设置成磁盘的IOPS,磁盘的IOPS可以通过fio这个工具来测试.

InnoDB的刷盘速度就是要参考两个因素:一个是脏页比例,一个是redo log写盘速度.

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210412185121650.png" alt="image-20210412185121650" style="zoom:33%;" />

### 4.3.刷脏页的"连坐"机制

在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。

## 5.为什么表数据删很多,表大小不变

### 5.1.参数innodb_file_per_table

一个InnoDB表包含两部分,即:表结构定义和数据.在MySQL8.0版本之前,表结构是存在.frm为后缀的文件里.而MySQL8.0版本,则已经允许把表结构定义放在系统数据表中了.

表数据既可以存在共享表空间,也可以是单独的文件.这个行为是由参数`innodb_file_per_table`控制的;

1. 这个参数设置为OFF表示的是,表的数据放在系统共享表空间,也就是跟数据字典放在一起;
2. 这个参数设置为ON表示的是,每个InnoDB表数据存储在一个以.ibd为后缀的文件中;

从MySQL5.6.6.版本开始,默认值就是ON了.无论使用MySQL的哪个版本,都建议将这个设置为ON.因为,一个表单独存储为一个文件更容易管理,而且在你不需要这个表的时候,通过drop table命令,系统就会直接删除这个文件,而如果是放在共享表空间中,即使表删除了,空间也是不会回收的.

将innodb_file_per_table设置为ON,是推荐做法,

### 5.2.数据删除流程

![image-20210413101833946](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210413101833946.png)

假设要删除掉R4这个记录,InnoDB只会把R4这个记录标记为删除.如果之后要再插入一个ID在300和600之间的记录,可能会复用这个位置.但是,磁盘文件的大小并不会缩小;InnoDB的数据是按页存储的,如果删掉一个数据页上的所有记录,整个数据页就可以被复用.

记录的复用,只限于符合范围条件的数据,而当整个页从B+树摘掉以后,可以复用到任何位置.如果相邻的两个数据页利用率都很小,系统就会把这两个页上的数据合到其中一个页上,另外一个数据页就被标记为复用.如果我们用delete命令把整个表的数据删除,结构就是,所有的数据页都会被标记为可复用.但是磁盘上,文件不会变小.delete命令其实只是把记录的位置,或者数据页标记为了可复用.但磁盘文件的大小是不会变的.也就是说,通过delet命令是不能回收表空间的.这些可以复用,而没有被使用的空间,看起来就像是空洞;

### 5.3.造成空洞的其它操作

如果数据是按照索引递增顺序插入,那么索引是紧凑的,但如果数据是随机插入的,就可能造成索引的数据页分裂.

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210413113313053.png" alt="image-20210413113313053" style="zoom:50%;" />

更新索引上的值,可以理解为删除一个旧的值,再插入一个新值,都会造成空洞,经过大量增删改的表,都是可能存在空洞的.

### 5.4.重建表

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210413113801249.png" alt="image-20210413113801249" style="zoom:50%;" />

可以使用`alter table A engine = InnoDB`命令重建表,在MySQL5.5.版本之前,这个命令的执行会自动创建临时表,然后完成转存数据,交换表名,删除旧表,花时间最多的步骤是往临时表插入数据的过程,如果在这个过程中,有新的数据要写入到表A的话,就会造成数据丢失,因此,在整个DDL过程中,表A不能有更新.在MySQL5.6之后引入Online DDL之后,对这个流程做了优化如下:

1. 建立一个临时文件,扫描表A主键的所有数据;
2. 用数据页中标A的记录生成B+树,存储到临时文件中;
3. 生成临时文件的过程中,将所有对A的操作记录在一个日志文件(row log)中,对应的是图中state2的状态;
4. 临时文件生成后,将日志文件的操作应用到临时文件,得到一个逻辑数据上与表A相同的数据文件,对应的就是图中state3的状态;
5. 用临时文件替换表A的数据文件;

在流程中,alter语句在启动的时候需要获取MDL写锁,但是这个写锁在真正拷贝数据之前就退化成读锁了,对于一个大表来说,Online DDL最耗时的过程就是拷贝数据到临时表的过程,这个步骤的执行期间可以接受数据的增删改操作.所以,相对于整个DDL过程来说,锁的时间非常短,对业务来说,就可以认为是online的;

### 5.5.Online和inplace

???

## 6.count(*)

### 6.1.count(*)的实现方式

首先要明确的是,在不同的MySQL引擎中,count(*)有不同的实现方式.前提是没有where过滤条件:

* MySAM引擎把一个表的总行数存在了磁盘上,因此执行count(*)的时候回直接返回这个数,效率很高;
* InnoDB引擎比较麻烦,它执行count(*)的时候,需要把数据一行一行地从引擎里面读出来,然后累计和计数;

在同一时刻的多个查询,由于多版本并发控制(MVCC)的原因,InnoDB表应该返回多少行也是不确定的.每一行都要判断自己是否对这个会话可见,因此对于count(\*)请求来说,InnoDB治好把数据一行一行地读出来依次判断,可见的行才能够用于计算"基于这个查询"的表的总行数;InnoDB是索引组织表,主键索引树的叶子节点是数据,而普通索引树的叶子节点是主键值.所以,普通索引树比主键索引树小很多.对于count(\*)这样的操作,无论遍历什么样的索引树得到的结果逻辑上都是一样的,因此,MySQL优化器会找到最小的那棵树来遍历.

### 6.2.show table status

能否用`show table status`中的TABLE_ROWS来代替count(*)吗,答案是不能,因为TABLE_ROWS就是从这个采样估算得来的.

### 6.3.用数据库保存计数

已理解

### 6.4.不同的count()用法

count()的语义是:**count()是一个聚合函数,对于返回的结果集,一行行地判断,如果count函数的参数不是NULL,累计值就加1,否则不加,最后返回累计值**.

* 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。
* 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。
* 对于count(字段)来说
  * 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；
  * 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加.
* count(\*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(\*) 肯定不是 null，按行累加。

所以结论是：count(字段)<count(主键)<count(1)≈count(*);

## 7.binlog和redo log如何配合

在两阶段提交的不同瞬间,MySQL如果发生异常重启,是怎么保证数据完整性的;

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210413181611486.png" alt="image-20210413181611486" style="zoom: 33%;" />

* 如果在图中时刻A的地方,也就是写入redo log处于prepare阶段之后,写binlog之前,发生了崩溃(crash),由于此时binlog还没写,redo log也还没提交,所以崩溃恢复的时候,这个事务会回滚,这时候,binlog还没写,所以也不会传到备库.
* 如果在图中时刻B,则有如下判断:
  * 如果redo log里面的事务是完整的,也就是已经有了commit标识,则直接提交;
  * 如果redo log里面的事务只有完整的prepare,则判断对应的事务binlog是否存在并完整;
    * 如果是,则提交事务;
    * 如果否,则回滚事务;

### 7.1.MySQL怎么知道binlog是完整的?

一个事务的binlog是由完整格式的:

* statement格式的binlog,最后会有COMMIT;
* row格式的binlog,最后会有一个XID event;

另外,在MySQL5.6.2.版本以后,还引入了binlog-checksum参数,用来验证binlog内容的正确性.对于binlog日志由于磁盘原因,可能会在日志中间出错的情况,MySQL可以通过捡钱checksum的结果来发现.所以,MySQL还是有办法验证事务binlog的完整性的;

### 7.2.redo log和binlog是怎么关联起来的?

他们有一个共同的数据字段,叫XID,崩溃恢复的时候,会按照顺序扫描redo log;

* 如果碰到既有prepare,又有commit的redo log,就直接提交;
* 如果碰到只有prepare,而没有commit的redo log,就拿着XID去binlog找对应的事务;

### 7.3.处于prepare阶段的redo log加上完整binlog,重启就能恢复?

在binlog写完以后MySQL发生崩溃,这时binlog已经写入了,之后就会被从库(或者用这个binlog恢复出来的库)使用.所以,在主库上也要提交这个事务.采用这个策略,主库和备库的数据就保证了一致性;

### 7.4.为什么需要两阶段提交?

两阶段提交是经典的分布式系统问题.对于InnoDB引擎来说,如果redo log提交完成了,事务就不能回滚了.而如果redo log直接提交,然后binlog写入的时候失败,InnoDB又回滚不了了,数据和binlog日志又不一致了;

### 7.5.只用binlog来支持崩溃恢复,又能支持归档,不可以吗?

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210414154250445.png" alt="image-20210414154250445" style="zoom:50%;" />

> binlog1是update c+1;binlog2是update c+1;现在在binlog2写完没提交的时候发生crash,这时对数据的更新可能还停留在内存中，并未刷盘，crash后内存数据丢失。 由于binlog2事务为完成，系统会应用binlog2恢复数据，即此时c+1;但对于binlog1来说，已经完成了事务，系统不会再应用binlog1来恢复数据，所以数据c不会再+1. 这时数据c只加了一次，与未crash前c+了两次不同 即binlog没有能力恢复数据页。。。。。
>
> 在图中这个位置崩溃的话，事务1可能只是redolog写进磁盘并且提交了，但是事务1更新的记录并没有刷盘，也就是丢失了。 但是恢复的时候我们只用binlog来恢复，这时候事务1显示是提交的，所以不会应用binlog，导致这块数据就丢失了。 因为binlog并不记录数据页级的丢失。 如果真想使用binlog来恢复的话，那么就要在每个commit之前，将更改的内存记录刷盘。刷盘之后再将这个事务改为commit状态。 这样崩溃恢复就可以在事务级去做了，而不用在数据页级去做了。

binlog 没有能力恢复“数据页”。如果在图中标的位置，也就是 binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。重启后，引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1 来说，系统已经认为提交完成了，不会再应用一次 binlog1。但是，InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。也就是说在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。你如果要说，那我优化一下 binlog 的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个 redo log 出来。所以，至少现在的 binlog 能力，还不能支持崩溃恢复。

### 7.6.只用redo log可以吗?

binlog有着redo log无法替代的功能.一个是归档.redo log是循环写,写到末尾要回到开头继续写,这样历史日志没法保留,redo log也就起不到归档作用;其中,MySQL系统高可用的基础,就是binlog复制.

### 7.7.数据写入后的最终落盘,是从redo log更新还是从buffer pool更新的?

redo log并没有记录数据页的完整数据,它并没有能力自己去更新磁盘数据页.实际情况分2种:

1. 如果是正常运行的实例的话,数据被修改以后,跟磁盘的数据页不一致,称为脏页.最终数据落盘,就是把内存中的数据页写盘,这个过程跟redo log无关;
2. 在崩溃恢复场景中,InnoDB如果判断一个数据页可能在崩溃恢复的时候丢失了更新,就会将它读到内存中,然后让redo log更新内存内容,更新完成后,内存页变成脏页,就回到了第一种情况;

### 7.8.redo log buffer是什么?是先修改内存,还是先写redo log?

~~~mysql

begin;
insert into t1 ...
insert into t2 ...
commit;
~~~

这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。

## 8.order by

## 9.




# 4.MySQL-实战3

[TOC]

## 1.数据被误删

数据被误删通常被分为:

* 使用delete语句误删数据行;
* 使用drop table或者truncate table语句误删数据表;
* 使用drop database语句误删数据库;
* 使用rm命令误删整个MySQL实例;

### 1.1.误删行

如果使用delete语句误删了行,可以用Flashback工具通过闪回把数据恢复过来.Flashback恢复数据的原理,是修改binlog的内容,拿回原库重放.而能够使用这个方案的前提是,需要确保`binlog_format=row`和`binlog_row_image=FULL`;

具体恢复数据时,对单个事务做如下处理:

1. 对于insert语句,对应的binlog event类型是`Write_rows_event`,把它改成Delete_rows_event即可;
2. 对于delete语句,也是将Delete_rows_event改为Write_rows_event;
3. 而如果是Update_rows的话,binlog里面记录了数据行修改前和修改后的值,对调这两行的位置即可;

如果误操作的不是一行,而是多个,Flashback解析binlog后会将事务调过来执行;

> 不建议在主库上执行这些操作,恢复数据比较安全的操作,是恢复一个备库,或者找一个库作为临时库,在这个临时库上执行这些操作,然后将确认过的临时库的数据.恢复回主库.

误删数据我们也要提前预防

> 1. 把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。
> 2. 代码上线前，必须经过 SQL 审计。

### 1.2.误删库/表

我们使用delete命令删除的数据可以通过Flashback来恢复,而使用truncate/drop table和drop database命令删除的数据,就没办法通过Flashback来恢复了.这是因为,即使我们配置了binlog_format=row,执行三个命令时,记录的binlog还是statement格式.binlog里面就只有一个truncate/drop语句,这些信息是恢复不出数据的.这种情况,就需要使用全量备份,加增量日志的方式了.这个方案要求线上有定期的全量备份,并且实时备份binlog;

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210417165421672.png" alt="image-20210417165421672" style="zoom:50%;" />

???

## 2.kill不掉的语句

## 3.查询大量语句会不会把数据库内存打爆?

### 3.1.全表扫描对server层的影响

假设,我们现在要对一个200G的InnoDB表db1.t,执行一个全表扫描.当然,你要把扫描结果保存在客户端.InnoDB的数据是保存在组件索引上的,所以全表扫描实际上是直接扫描t的主键索引.由于`select * from db1.t`没有其它的判断条件,所以查到的每一行都可以直接放到结果集里面,然后返回到客户端.\

服务端并不需要保存一个完整的结果集,取数据和发数据的流程如下:

1. 获取一行,写到net_buffer中,这块内存的大小是由参数`net_buffer_length`定义的,默认是16k;
2. 重复获取行,直到net_buffer写满,调用网络接口发出去;
3. 如果发送成功,就清空net_buffer,然后继续取下一行,并写入net_buffer;
4. 如果发送函数返回EAGAIN或WSAEWOULDBLOCK就表示本地网络栈(socket send buffer)写满了,进入等待,直到网络栈重新可写,再继续发送.

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418103250397.png" alt="image-20210418103250397" style="zoom: 33%;" />

从这个流程中,可以看到:

1. 一个查询在发送过程中,占用的MySQL内部的内存最大就是`net_buffer_length`这么大,并不会达到200G;
2. socket send buffer也不可能达到200G(默认定义`/proc/sys/net/core/wmem_default`),如果`socket send buffer`被写满,就会暂停读数据的流程;

MySQL是"边读边发",这个概念很重要,这就意味着,如果客户端接收得慢,会导致MySQL服务端由于结果发布出去,这个事务的执行时间边长.

![image-20210418113803383](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418113803383.png)

如果看到的State的值一直处于`Sending to client`,就表示服务器端的网络栈写满了.如果客户端使用`-quick`参数,会使用`mysql_use_result`方法,这个方法是读一行处理一行,假设有一个业务的逻辑比较复杂,每读一行数据以后要处理的逻辑如果很慢,就会导致哭护短要过很久才会去取下一行数据.对于正常的线上业务来说,如果一个查询的返回结果不会很多的话,都建议使用`mysql_store_result`这个接口,直接把查询结果保存到本地内存.如果执行了一个大查询导致客户端占用接近20G,这种情况就需要改用`mysql_use_result`接口了.

如果看到MySQL里有很多线程都处于`Sending to client`这个状态,这就以为这需要优化了,如果要快速减少处于这个状态的线程的话,将`net_buffer_length`参数设置为一个更大的值是一个可选的方案.

#### 3.1.1.Sending data与Sending to client

一个查询语句的状态变化:

1. MySQL查询语句进入执行阶段后,首先把状态设置成`Sending data`;
2. 然后,发送执行结果的列相关信息(meta data)给客户端;
3. 再继续执行语句流程;
4. 执行完成后,把状态设置成空字符串;

也就是说,"Sending data"并不一定是指正在发送数据,而可能是处于执行器过程中的任意阶段.仅当一个线程处于"等待客户端接收结果"的状态,才会显示"Sending to client";

### 3.2.全表扫描对InnoDB的影响

Buffer Pool有加速查询的作用,而Buffer Pool对查询的加速效果,依赖于一个重要的指标,即**内存命中率**;在`show engine innodb status`结果中,查看一个系统当前的BP命中率.一般情况下,一个稳定服务的线上系统,要保证响应时间符合要求的话,内存命中率在99%以上.执行`show engine innodb status`,可以看到"Buffer pool hit rate"显示的就是当前命中率:

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418141653649.png" alt="image-20210418141653649" style="zoom:50%;" />

InnoDB Buffer Pool的大小是由参数`innodb_buffer_pool_size`确定的,一般建议设置成可用物理内存的60%-80%;InnoDB内存管理用的是最近最少使用(Least Recently Used,LRU)算法,这个算法的核心就是淘汰最久未使用的数据.

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418142029588.png" alt="image-20210418142029588" style="zoom:50%;" />

#### 3.2.1.LRU算法

InnoDB管理Buffer Pool的LRU算法,使用链表来实现的.

1. 在上图的状态1中,链表头部是P1,表示P1是最近刚刚被访问过的数据页,假设内存里只能放下这么多数据页;
2. 这时候有一个读请求访问P3,因此变为状态2,P3被移到最前面;
3. 状态3表示,这次访问的数据页是不存在与链表中,所以需要在Buffer Pool中新申请一个数据页Px.加到链表头部.由于内存已经满了,不能申请新的内存,于是会清空链表末尾Pm这个数据页的内容,存入Px的内容,然后放到链表头部.
4. 从效果上看,就是最久没被访问的数据页Pm被淘汰了;

#### 3.2.2.InnoDB对LRU算法的改进

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418144245170.png" alt="image-20210418144245170" style="zoom:33%;" />

在InnoDB实现上,按照5:3的比例把整个LRU链表分层了young区域和old区域.图中LRU_old指向的就是old区域的第一个位置,是整个链表的5/8处.也就是说,靠近链表头部的5/8是young区域,靠近链表尾部的3/8区域是old区域;

1. 图 7中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。
2. 之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。
3. 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：
   1. 若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；
   2. 如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。

刚刚扫描200G的历史数据表为例,改进后的LRU算法操作逻辑:

1. 扫描过程中，需要新插入的数据页，都被放到 old 区域 ;
2. 一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过 1 秒，因此还是会被保留在 old 区域；
3. 再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是 young 区域），很快就会被淘汰出去。

## 4. join语句

~~~sql
CREATE TABLE `t2` (
  `id` int(11) NOT NULL,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `a` (`a`)
) ENGINE=InnoDB;

drop procedure idata;
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=1000)do
    insert into t2 values(i, i, i);
    set i=i+1;
  end while;
end;;
delimiter ;
call idata();

create table t1 like t2;
insert into t1 (select * from t2 where id<=100)
~~~

这两张表都有一个主键索引id和一个索引a,字段b上无索引.存储过程`idata()`往表t2里插入了1000行数据,在表t1里插入的是100行数据.

### 4.1.Index Nested-loop join(NLJ)

```sql
select * from t1 straight_join t2 on (t1.a=t2.a);
```

在这个语句里,t1是驱动表,t2是被驱动表;

![image-20210418155050248](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418155050248.png)

1. 从表 t1 中读入一行数据 R；
2. 从数据行 R 中，取出 a 字段到表 t2 里去查找；
3. 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；
4. 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。

![image-20210418155214746](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418155214746.png)

在这个流程中:

1. 对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行；
2. 而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。
3. 由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；
4. 所以，整个执行流程，总扫描行数是 200。

在这个 join 语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。假设被驱动表的行数是 M。每次在被驱动表查一行数据，要先搜索索引 a，再搜索主键索引。每次搜索一棵树近似复杂度是以 2 为底的 M 的对数，记为 log2M，所以在被驱动表上查一行的时间复杂度是 2\*log2M。整个执行过程，近似复杂度是 N + N*2*log2M。

显然N对扫描行数的影响更大,应该让小表做驱动表,当然这个结论的前提是"可以使用被驱动表的索引";

### 4.2.Simple Nested-Loop join

~~~sql
select * from t1 straight_join t2 on (t1.a=t2.b);
~~~

该方法扫描数据的行数太多,MySQL没有适用这个Simple Nested-Loop Join算法,而是使用了另一个叫做`Block Nested-Loop Join`算法;

### 4.3.Block Nested-Loop join(BNL)

被驱动表上没有可用的索引,算法流程是:

1. 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；
2. 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418160431760.png" alt="image-20210418160431760" style="zoom:50%;" />

![image-20210418160515725](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418160515725.png)

在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000=10 万次。前面我们说过，如果使用 Simple Nested-Loop Join 算法进行查询，扫描行数也是 10 万行。因此，从时间复杂度上来说，这两个算法是一样的。但是，Block Nested-Loop Join 算法的这 10 万次判断是内存操作，速度上会快很多，性能也更好。

要是表 t1 是一个大表，join_buffer 放不下怎么办呢？join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，策略很简单，就是分段放。

1. 扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；
2. 扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；
3. 清空 join_buffer；
4. 继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。

![image-20210418160857123](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418160857123.png)

所以如果join语句很慢的话,就把`join_buffer_size`改大一些.

如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？

1. 如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；
2. 如果是 Block Nested-Loop Join 算法：
   1. 在 join_buffer_size 足够大的时候，是一样的；
   2. 在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。

所以，这个问题的结论就是，总是应该使用小表做驱动表。

**在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。**

## 5.join语句优化

~~~sql
create table t1(id int primary key, a int, b int, index(a));
create table t2 like t1;
drop procedure idata;
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=1000)do
    insert into t1 values(i, 1001-i, i);
    set i=i+1;
  end while;
  
  set i=1;
  while(i<=1000000)do
    insert into t2 values(i, i, i);
    set i=i+1;
  end while;

end;;
delimiter ;
call idata();
~~~

在表 t1 里，插入了 1000 行数据，每一行的 a=1001-id 的值。也就是说，表 t1 中字段 a 是逆序的。同时，在表 t2 中插入了 100 万行数据。

### 5.1.Multi-Range Read优化(MRR)

~~~sql
select * from t1 where a>=1 and a<=100;
~~~

主键索引是一颗B+数,在这颗树上,每次只能根据一个主键id查到一行数据.因此,回表肯定是一行一行搜索主键索引的,基本流程如下:

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418162821739.png" alt="image-20210418162821739" style="zoom:50%;" />

如果随着a的值递增顺序查询的话,id的值就变成随机的,那么就会出现随机访问.性能相对较差.因此大多数的数据都是按照主键递增顺序插入得到的,所以可以认为,如果按照主键的递增顺序查询的话,对磁盘的读比较接近顺序读,能够提升读性能.

MRR优化如下:

1. 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;
2. 将 read_rnd_buffer 中的 id 进行递增排序；
3. 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。

这里,`read_rnd_buffer`的大小是由`read_rnd_buffer_size`参数控制的,如果步骤1中,read_rnd_buffer放满了,就会先执行完步骤2和步骤3,然后清空read_rnd_buffer.之后继续找索引a的下个记录,并继续循环.另外,如果你想要稳定地使用 MRR 优化的话，需要设置`set optimizer_switch="mrr_cost_based=off"`。（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用 MRR，把 mrr_cost_based 设置为 off，就是固定使用 MRR 了。）

![image-20210418171950849](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418171950849.png)

![image-20210418172024864](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418172024864.png)

MRR能够提升性能的核心在于,这条查询语句在索引a上做的是一个范围查询(也就是说,这是一个多值查询),可以得到足够多的主键id.这样通过排序后,再去主键索引查数据,才能体现出"顺序性"的优势;

### 5.2.Batched Key Access(BKA)

BKA算法其实就是对NLJ算法的优化.

NLJ算法执行的逻辑:从驱动表t1,一行行地取出a的值,再到被驱动表t2去做join.对于表t2来说,每次都是匹配一个值.这时,MRR的优势就用不上了.我们把表t1的数据取出来一部分,先放到join_buffer中.

![image-20210418172627787](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210418172627787.png)

如果要使用BKA优化算法的话,需要在执行SQL之前,先设置`set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';`

### 5.3.BNL算法的性能问题

由于 InnoDB 对 Bufffer Pool 的 LRU 算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在 old 区域。如果 1 秒之后这个数据页不再被访问了，就不会被移动到 LRU 链表头部，这样对 Buffer Pool 的命中率影响就不大。但是，如果一个使用 BNL 算法的 join 语句，多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部。这种情况对应的，是冷表的数据量小于整个 Buffer Pool 的 3/8，能够完全放入 old 区域的情况。如果这个冷表很大，就会出现另外一种情况：业务正常访问的数据页，没有机会进入 young 区域。由于优化机制的存在，一个正常访问的数据页，要进入 young 区域，需要隔 1 秒后再次被访问到。但是，由于我们的 join 语句在循环读磁盘和淘汰内存页，进入 old 区域的数据页，很可能在 1 秒之内就被淘汰了。这样，就会导致这个 MySQL 实例的 Buffer Pool 在这段时间内，young 区域的数据页没有被合理地淘汰。

为了减少这种影响,可以考虑增大`join_buffer_size`的值,减少对被驱动表的扫描次数;

也就是说,BNL算法对系统的影响主要包括三个方面:

1. 可能会多次扫描被驱动表,占用磁盘IO资源;
2. 判断join条件需要执行M*N次对比(M,N分别是两张表的行数),如果是达标就会占用非常多的CPU资源;
3. 可能会导致Buffer Pool的热数据被淘汰,影响内存命中率;

### 5.4.BNL转BKA

一些情况下,可以直接在被驱动表上建索引,这时就可以直接转成BKA算法了;当然也可以用临时表,不论是在原表上加索引还是用索引的临时表,思路都是让join语句能够用上被驱动表上的索引,触发BKA算法,提升查询性能.

## 6.临时表

### 6.1.临时表和内存表

* 内存表:指的是使用Memory引擎的表,建表语法是`create table ... engine=memory;`,这种表的数据都保存在内存里,系统重启的时候被清空,但是表结构还在.
* 临时表:可以使用各种引擎类型,如果是使用InnoDB引擎或者MyISAM引擎的临时表,写数据的时候是写到磁盘上的,当然临时表也可以使用Memory引擎;

### 6.2.临时表的特性

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419102218611.png" alt="image-20210419102218611" style="zoom:50%;" />

* 建表语法是`create temporary table...`;
* 一个临时表只能被创建它的session访问,对其他线程不可见.所以,图中session A创建的临时表t,对于session B就是不可见的;
* 临时表可以与普通表同名;
* session A内有同名的临时表和普通表的时候,show create 语句,以及增删改查语句访问的是临时表;
* show tables命令不显示临时表;

### 6.3.临时表的应用

由于不用担心线程之间的重名冲突,临时表经常用在复杂查询的优化过程中.其中,分库分表系统的跨库查询就是典型的使用场景.一般分库分表的场景就是要把一个逻辑上的大表分散到不同的数据库实例上.比如,将一个大表ht,按照字段f,拆分成1024个表,然后分布到32个数据库实例上,如下图所示.

![image-20210419104106095](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419104106095.png)

~~~sql
select v from ht where k >= M order by t_modified desc limit 100;
~~~

**第一种思路**在proxy层的进程代码中实现排序

这种方式的优势是处理速度快,拿到分库的数据后,直接在内存中参与计算,这个方案的缺点很明显:

1. 需要的开发工作量比较大,如果涉及到复杂的操作,对中间层的开发能力要求比较高;

2. 对proxy端的压力比较大,尤其是很容易出现内存不够用和CPU瓶颈问题;

**另一种思路**把各个分库拿到的数据,汇总到一个MySQL实例的一个表中,然后在汇总实例上做逻辑操作;

![image-20210419104506688](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419104506688.png)

### 6.4.为什么临时表可以重名?

```sql
create temporary table temp_t(id int primary key)engine=innodb;
```

在执行上面的语句的时候,MySQL要给这个InnoDB创建一个frm文件保存表结构定义,还要有地方保存表数据.这个frm文件放在临时文件目录下,文件名的后缀是.frm,前缀是"#sql{进程 id}\_{线程 id}\_序列号".可以使用`select@@tmpdir`命令来显示实例的临时文件目录;

* 在 5.6 以及之前的版本里，MySQL 会在临时文件目录下创建一个相同前缀、以.ibd 为后缀的文件，用来存放数据文件；
* 而从 5.7 版本开始，MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据。

从文件名的前缀规则,其实创作一个叫t1的InnoDB临时表,MySQL在存储上认为我们创建的表名跟普通表t1是不同的,因此同一个库下面已经有普通表t1的情况下,还是可以再创建一个临时表t1;

MySQL维护数据表,除了物理上要有文件外,内存里面也有一套机制区别不同的表,每个表都对应一个table_def_key.

* 一个普通表的 table_def_key 的值是由“库名 + 表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现 table_def_key 已经存在了。
* 而对于临时表，table_def_key 在“库名 + 表名”基础上，又加入了“server_id+thread_id”。

在实现上,每个线程都维护人自己的临时表链表.这样每次session内操作表的时候,先遍历链表,检查是否有这个名字的临时表,如果有就有限操作临时表,如果没有再操作普通表,在session结束的时候,对链表里的每个临时表,执行"DROP TEMPORARY TABLE + 表名"操作;

### 6.5.临时表和主备复制

~~~sql
create table t_normal(id int primary key, c int)engine=innodb;/*Q1*/
create temporary table temp_t like t_normal;/*Q2*/
insert into temp_t values(1,1);/*Q3*/
insert into t_normal select * from temp_t;/*Q4*/
~~~

在主库上执行上面的语句.

如果关于临时表的操作都不记录，那么在备库就只有 create table t_normal 表和 insert into t_normal select * from temp_t 这两个语句的 binlog 日志，备库在执行到 insert into t_normal 的时候，就会报错“表 temp_t 不存在”。

如果把binlog设置为row格式时,在记录`insert into t_normal`的binlog时,记录的是这个操作的数据:write_row_event里面记录的逻辑是"插入一行数据(1,1)";所以说,如果当前`binlog_format=row`,那么临时表有关的语句,就不会记录到binlog里,也就是说,只在binlog_format=statment/mixed的时候,binlog中才会记录临时表的操作;所以说,主库在线程退出的时候,会自动删除临时表,并且再写一个`DROP TEMPORARY TABLE`传给备库执行;

主库上不同的线程创建同名的临时表示没有关系的,传到备库执行是怎么处理的?

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419135043721.png" alt="image-20210419135043721" style="zoom: 50%;" />

MySQL在记录binlog的时候,会把主库执行这个语句的线程id写到binlog中.这样,在备库的应用线程就能够知道每个语句的主库线程id,并利用这个线程id来构造临时表的table_def_key:

1. session A 的临时表 t1，在备库的 table_def_key 就是：库名 +t1+“M 的 serverid”+“session A 的 thread_id”;
2. session B 的临时表 t1，在备库的 table_def_key 就是 ：库名 +t1+“M 的 serverid”+“session B 的 thread_id”。

由于table_def_key不同,所以这两个表在备库的应用线程里面是不会冲突的.

## 7.内部临时表

### 7.1.union执行流程

~~~sql
(select 1000 as f) union (select id from t1 order by id desc limit 2);
~~~

这条语句用到了union,它的语义是,取这两个子查询结果的并集.并集的意思就是这两个集合加起来,重复行只保留一行.

![image-20210419140127140](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419140127140.png)

这个语句的执行流程如下:

1. 创建一个内部临时表,这个临时表只有一个整型字段f,并且f是主键字段;
2. 执行第一个子查询,得到1000这个值,并存入临时表中;
3. 执行第二个子查询:
   1. 拿到第一行id=1000,视图插入临时表中.但由于1000这个值已经存在于临时表中,违反了唯一性约束,所以插入失败,然后继续执行;
   2. 取第二行id=999,插入临时表成功;
4. 从临时表中按行取出数据,返回结果,并删除临时表,结果中包含两行数据分别是1000和999;

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419140439447.png" alt="image-20210419140439447" style="zoom:50%;" />

可以看到,这里的内存临时表起到了暂存数据的作用,而且计算过程还用上临时表主键id的唯一性约束,实现了union的语义.

如果把上面的这个语句中的union改成union all的话,就没了"去重"的语义.这样执行的时候,就依次执行子查询,得到的结果直接作为结果集的一部分发给客户端,因此就不需要临时表了.

![image-20210419170135061](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419170135061.png)

### 7.2.group by 执行流程

```sql
select id%10 as m, count(*) as c from t1 group by m;
```

![image-20210419170343409](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419170343409.png)

这个语句的逻辑是表表t1里的数据,按照id%10进行分组统计,并按照m的结果排序后输出,它的explain结果如上:

1. 创建内存临时表,表里有两个字段m和c,主键是m;
2. 扫描表t1的索引a,依次取出叶子节点上的id值,计算id%10的结果,记为x;
   1. 如果临时表中没有主键为x的行,就插入一个记录(x,1);
   2. 如果表中有主键为x的行,就将x这一行的c值加1;
3. 遍历完成后,再根据字段m做排序,得到结果集返回给客户端;

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419171017371.png" alt="image-20210419171017371" style="zoom:50%;" />

![image-20210419171128466](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419171128466.png)

如果并不需要对结果进行排序,那么可以在SQL语句末尾增加order by null,也就是改成:

~~~sql
select id%10 as m, count(*) as c from t1 group by m order by null;
~~~

上述例子全程只使用内存临时表,但是,内存临时表的大小是有限制的,参数`tmp_table_size`就是控制内存的大小.默认是16M;如果说内存执行过程中发现内存临时表大小达到了上线,那么就会把内存临时表转成磁盘临时表,磁盘临时表默认使用的引擎是InnoDB.

### 7.3.group by优化方法-索引

可以看到,不管是使用内存临时表还是磁盘临时表,group by逻辑都需要构造一个带唯一索引的表,执行代价比较高,如果表的数据量比较大,上面的group by语句执行起来就会很慢.group by的语义逻辑是统计不同的值出现的个数.但是,由于每一行的id%100的结果是无序的,所以需要有一个临时表,来记录并且统计结果.

在MySQL5.7版本支持了generated column机制,用来实现数据的关联更新.可以用下面的方法创建一个列z,然后在z列上创建一个索引(如果是MySQL5.6及之前的版本,可以创建普通列和索引来解决问题).

~~~SQL
alter table t1 add column z int generated always as(id % 100), add index(z);
select z, count(*) as c from t1 group by z;
~~~

![image-20210419175053090](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419175053090.png)

可以看到,这个语句不需要临时表了,也不需要排序了;

### 7.4.group by优化方法-直接排序

在group by语句中加入`SQL_BIG_RESULT`这个提示(hint),就可以告诉优化器:这个语句涉及的数据量很大,直接使用磁盘临时表.

~~~SQL
select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;
~~~

1. 初始化 sort_buffer，确定放入一个整型字段，记为 m；
2. 扫描表 t1 的索引 a，依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中；
3. 扫描完成后，对 sort_buffer 的字段 m 做排序（如果 sort_buffer 内存不够用，就会利用磁盘临时文件辅助排序）；
4. 排序完成后，就得到了一个有序数组。

![image-20210419180035490](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419180035490.png)

![image-20210419180147029](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210419180147029.png)

### 7.5.MySQL什么时候会使用内部临时表

1. 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；
2. join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；
3. 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。

## 8.Memory引擎

### 8.1.内存表的数据组织结构

~~~SQL
create table t1(id int primary key, c int) engine=Memory;
create table t2(id int primary key, c int) engine=innodb;
insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
~~~

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210420104256408.png" alt="image-20210420104256408" style="zoom:50%;" />

可以看到,内存表t1的返回结果里面0在最后一行,而InnoDB表t2的返回结果里0在第一行.出现这个问题的原因是跟两个表的主键索引的组织方式有关.与InnoDB引擎不同,Memory引擎的数据和索引是分开的.

![image-20210420104908136](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210420104908136.png)

内存表的数据部分以数据的方式单独存放,而主键id索引里,存的是每个数据的位置,主键id是hash索引,可以看到索引上的key并不是有序的;在内存表t1中,当执行`select *`的时候,走的是全表扫描,也就是顺序扫描这个数组.因此,0就是最后一个被读到,并放入结果集的数据.

* InnoDB引擎把数据放在主键索引上,其他索引上保存的是主键id.这种方式,叫做**索引组织表(index Organizied Table)**;
* Memory引擎采用的是把数据单独存放,索引上保存数据位置的数据组织形式,称为**堆组织表(Heap Organizied Table)**;

### 8.2.Memory和InnoDB的不同

* InnoDB表的数据总是有序存放,而内存表的数据就是按照写入顺序存放的;
* 当数据文件有空洞的时候,InnoDB表在插入新数据的时候,为了保证数据有序性,只能在固定的位置写入新值,而内存表找到空为就可以插入新值;
* 数据位置发生变化的时候,InnoDB表只需要修改主键索引,而内存表需要修改所有索引;
* InnoDB表用主键索引查询时需要走一次索引查找,用普通索引查询的时候,需要走两次索引查找.内存表没有这个区别,所有索引的地位都是相同的;
* InnoDB支持变长数据类型,不同记录的长度可能不同;内存表不支持Blob和Text字段,并且即使定义了varchar(N),实际也当做char(N),也就是固定长度字符串来存储,因此内存表的每行数据长度相同;

由于内存表的这些特性,每个数据行被删除以后,空出的这个位置都可以被接下来要插入的数据复用.并且需要注意的是.如果执行的是范围查询,是用不上主键索引的,需要走全表扫描;

### 8.3.hash索引和B-Tree索引

内存表也是支持B-Tree索引的,在id列上创建一个B-Tree索引,可以这么写:

~~~sql
alter table t1 add index a_btree_index using btree (id);
~~~

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210420112253532.png" alt="image-20210420112253532" style="zoom:33%;" />

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210420112414659.png" alt="image-20210420112414659" style="zoom:33%;" />

可以看到,执行`select * from t1 where id <5`的时候,优化器会选择B-Tree索引,所以返回结果是0到4,使用force index强行使用主键id这个索引,id=0这一行就在结果集的最末尾了;

### 8.4.内存表的锁

内存表不支持行锁,只支持表锁.因此,一张表只要有更新,就会堵住其他所有在这个表上的读写操作.

### 8.5.内存表的数据持久

在高可用架构下.内存表的异常重庆,然后被清空要被看作成Bug;

#### 8.5.1.M-S架构

1. 业务正常访问主库;
2. 备库硬件升级,备库重启,内存表t1内容被清空;
3. 备库重启后,客户端发送一条update语句,修改表t1的数据行,这时备库应用线程就会报错"找不到要更新的行";

这样就会导致主备同步停止,当然,这时候发生主备切换的话,客户端会看到表t1丢失了;

#### 8.5.2.M-M架构

在备库重启的时候,备库的binlog里的delete语句就会传到主库,然后把主库内存表的内容删除;

### 8.6.内存表的使用场景

~~~SQL
create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;
insert into temp_t select * from t2 where b>=1 and b<=2000;
select * from t1 join temp_t on (t1.b=temp_t.b);
~~~

这里其实使用内存临时表更好,原因如下:

1. 相比于InnoDB表,使用内存表不需要写磁盘,往表temp_t的写数据,往表temp_t的写数据的速度更快;
2. 索引b使用hash索引,查找的速度比B-Tree索引快;
3. 临时表数据只有2000行,占用的内存有限;

改代码如下:

~~~SQL
create temporary table temp_t(id int primary key, a int, b int, index (b))engine=memory;
insert into temp_t select * from t2 where b>=1 and b<=2000;
select * from t1 join temp_t on (t1.b=temp_t.b);
~~~

## 9.自增主键不连续?

### 9.1.自增值保存位置

在这个表t里面执行`insert into t values(null,1,1);`插入一行数据,再执行`show create table;`命令可以查看如下:

![image-20210420140618616](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210420140618616.png)

表定义中是`AUTO_INCREMENT=2`表示下一次插入数据时,如果需要自动生成自增值,会生成id=2;其实,这个输出结果容易引起这样的误解:自增值是保存在表结构定义里的.实际上,**表的结构定义存放在后缀名.frm的文件中,但是并不会保存自增值;**

不同的引擎对于自增值的保存策略不同:

* MySAM引擎的自增值保存在数据文件中;
* InnoDB引擎的自增值,其实是保存在内存里,并且到了MySQL8.0版本后,才有了"自增持久化"的能力,也就是才实现了"如果发生重启,表的自增值可以恢复为MySQL重启前的值",具体情况如下:
  * 在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。﻿举例来说，如果一个表当前数据行里最大的 id 是 10，AUTO_INCREMENT=11。这时候，我们删除 id=10 的行，AUTO_INCREMENT 还是 11。但如果马上重启实例，重启后这个表的 AUTO_INCREMENT 就会变成 10。﻿也就是说，MySQL 重启可能会修改一个表的 AUTO_INCREMENT 的值。
  * 在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。

### 9.2.自增值修改机制

在MySQL里面,如果字段id被定义为AUTO_INCREMENT,在插入一行数据的时候,自增值的行为如下:

1. 如果插入数据时id字段指定为0,null或者未指定值,那么就把这个表当前的AUTO_INCREMENT值增加到自增字段;
2. 如果插入数据时id字段指定了具体的值,就直接使用语句里指定的值;

根据要插入的值和当前自增的大小关系,自增值的变更结果或许有所不同.假设,某次要插入的值是x,当前的自增值是Y:

1. 如果 X<Y,那么这个表的自增值不变;
2. 如果X>=Y,就需要把当前自增值修改为新的自增值;

新的自增值生成的算法是:从`auto_increment_offset`开始,以`auto__increment`为步长,持续叠加,直到找到第一个大于X的值,作为新的自增值;默认值都是1;

> 在一些场景下，使用的就不全是默认值。比如，双 M 的主备结构里要求双写的时候，我们就可能会设置成 auto_increment_increment=2，让一个库的自增 id 都是奇数，另一个库的自增 id 都是偶数，避免两个库生成的主键发生冲突。

### 9.3.自增值的修改时机

#### 9.3.1.唯一键冲突导致不连续

假设,表t中已经有(1,1,1)这条记录.这时再执行一条插入数据命令:

```SQL
insert into t values(null, 1, 1); 
```

1. 执行器调用InnoDB引擎接口写入一行,传入的这一行的值是(0,1,1);
2. InnoDB发现用户没有指定自增id的值,获取表t当前的自增值2;
3. 将传入的行的值改成(2,1,1);
4. 将表的自增值改成3;
5. 继续执行插入操作,由于已经存在c=1的记录,所以报`Duplicate key error `,语句返回;

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210420150940412.png" alt="image-20210420150940412" style="zoom:33%;" />

这个表的自增值改成 3，是在真正执行插入数据的操作之前。这个语句真正执行的时候，因为碰到唯一键 c 冲突，所以 id=2 这一行并没有插入成功，但也没有将自增值再改回去。

#### 9.3.2.事务回滚导致不连续

~~~SQL
insert into t values(null,1,1);
begin;
insert into t values(null,2,2);
rollback;
insert into t values(null,2,2);
//插入的行是(3,2,2)
~~~

#### 9.3.3.自增值为什么不能回退

假设有两个并行执行的事务，在申请自增值的时候，为了避免两个事务申请到相同的自增 id，肯定要加锁，然后顺序申请。

1. 假设事务 A 申请到了 id=2， 事务 B 申请到 id=3，那么这时候表 t 的自增值是 4，之后继续执行。
2. 事务 B 正确提交了，但事务 A 出现了唯一键冲突。
3. 如果允许事务 A 把自增 id 回退，也就是把表 t 的当前自增值改回 2，那么就会出现这样的情况：表里面已经有 id=3 的行，而当前的自增 id 值是 2。
4. 接下来，继续执行的其他事务就会申请到 id=2，然后再申请到 id=3。这时，就会出现插入语句报错“主键冲突”。

因此InnoDB才保证了自增id是递增的,但不保证是连续的.

### 9.4.自增锁的优化

在MySQL5.0版本的时候,自增锁的范围是语句级别.也就是说,如果一个语句申请了一个表自增说,这个锁会等语句执行结束以后才释放.显然,这样设计会影响并发度.MySQL5.1.22.版本引入了一个新策略,新增参数`innodb_autoinc_lock_mode`默认值是1;

1. 这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略，即语句执行结束后才释放锁；
2. 这个参数的值被设置为 1 时：
   1. 普通 insert 语句，自增锁在申请之后就马上释放；
   2. 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；
3. 这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁。


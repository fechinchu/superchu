# 2.MySQL-实战2

[TOC]

## 1.SQL逻辑相同,性能差异巨大

### 1.1.条件字段函数操作

如果对MySQL条件字段做了函数计算,就用不上索引了.这是MySQL的规定;为什么条件是`where t_modified = '2018-7-1'`的时候可以用上索引,而改成`where month(t_modified)=7`的时候就不行了?

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210414210036161.png" alt="image-20210414210036161" style="zoom: 50%;" />

如果你的SQL语句条件用的是`where t_modified = '2018-7-1'`的话,引擎会按照上面绿色箭头的路线,定位到结果;实际上,B+树提供的这个快速定位的能力,来源于同一层兄弟节点的有序性.对索引字段做函数操作,可能会破坏索引值的有序性,因此优化器就决定放弃走树搜索功能.

在这个例子里,放弃了树搜索功能,优化器可以选择遍历主键索引,也可以选择遍历索引t_modified,优化器对比索引大小后发现,索引t_modified更小,遍历这个索引比遍历主键索引来得更快.因此最终还是会选择索引t_modified;,也是就是说,由于在t_modified字段加入month()函数操作,导致了全索引扫描.

### 1.2.隐式类型转化

```SQL
select * from tradelog where tradeid = 110717;
```

tradeid 的字段类型是varchar(32),而输入的参数却是整型,所以需要做类型转换;

#### 1.2.1.类型转换的规则

看`select "10" > 9`的结果;

1.  如果规则是"将字符串转成数字",那么就是做数字比较,结果应该是1;
2. 如果规则是"将数字转成字符串",那么就是做字符串比较,结果应该是0;

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210414232602179.png" alt="image-20210414232602179" style="zoom:33%;" />

所以上面的SQL语句,对于优化器来说,这个语句相当于:

```java
mysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;
```

这条语句触发了:对索引字段做函数操作,优化器会放弃走树搜索功能.

### 1.3.隐式字符编码转换

道理跟隐式类型转换是一样的

## 2.只查一行的语句,也执行很慢

### 2.1.查询长时间不返回

#### 2.1.1.场景一:等待MDL锁

可以使用`show processlist`命令查看`Waiting for table metadata lock`的示意图;

![image-20210414234410148](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210414234410148.png)

出现这个状态表示的是,现在有一个线程正在表t上请求或者持有MDL写锁,把select语句堵住了;我们可以通过查询`sys.schema_table_lock_waits`这张表,就可以直接找出造成阻塞的process id,把这个连接kill命令断开;

![image-20210414234927981](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210414234927981.png)

#### 2.1.2.场景二:等flush

```sql
select * from information_schema.processlist;
```

之后进行排查![image-20210414235432028](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210414235432028.png)

#### 2.1.3.场景三:等行锁

~~~sql

mysql> select * from t where id=1 lock in share mode; 
~~~

由于访问id = 1这个记录时要加读锁,如果这时候已经有一个事务在这行记录上持有一个写锁,select会被堵住;

### 2.2.查询慢

## 3.幻读

### 3.1.幻读是什么?

~~~sql

CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
~~~

![image-20210415112246071](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415112246071.png)

session A里执行了三次查询,分别是Q1,Q2,Q3.这语句的意思是使用的当前读.并且加上锁写锁;

> 在同一个事务中,两次读取到的数据不一致的情况称为幻读和不可重复读,幻读是针对insert导致的数据不一致,不可重复读是针对delete,update导致的数据不一致;

幻读的说明:

1. 在可重复读隔离级别下,普通的查询是快照读,是不会看到别的事务插入的数据的.因此,幻读在"当前读"下才会出现;
2. 上面session B修改结果,被session A之后之后的select语句用当前读看到,不能称为幻读,幻读仅专指"新插入的行";

### 3.2.幻读的问题

session A在T1时刻就声明了,"我要把所有d=5的行锁住,不准别的事务进行读写操作".而实际上,.这个语义被破坏了

其次是数据不一致的问题

![image-20210415142621598](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415142621598.png)

1. 经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ;
2. 经过 T2 时刻，id=0 这一行变成 (0,5,5);
3. 经过 T4 时刻，表里面多了一行 (1,5,5);
4. 其他行跟这个执行序列无关，保持不变。

binlog里面的内容:

1. T2 时刻，session B 事务提交，写入了两条语句；
2. T4 时刻，session C 事务提交，写入了两条语句；
3. T6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 这条语句。

放到一起就是这样:

~~~sql

update t set d=5 where id=0; /*(0,0,5)*/
update t set c=5 where id=0; /*(0,5,5)*/

insert into t values(1,1,5); /*(1,1,5)*/
update t set c=5 where id=1; /*(1,5,5)*/

update t set d=100 where d=5;/*所有d=5的行，d改成100*/
~~~

这个语句序列,不论是拿到备库去执行,还是以后用binlog来克隆,这三行的结果都变成了(0,5,100)、(1,5,100) 和 (5,5,100),发生了数据不一致.而且,即使把所有的记录都加上锁,还是阻止不了新插入的记录.

### 3.3.如何解决幻读?

#### 3.3.1.间隙锁

产生幻读的原因是,行锁只能锁住行,但是新插入记录这个动作,要更新的是记录是记录之间的"间隙".InnoDB引入了间隙锁(Gap Lock);

数据行是可以加上锁的实体,数据行之间的间隙,也是可以加上锁的实体.当执行`select * from where d=5 for update`的时候,就不止是给数据库中已有的6个记录加上了行锁,还同时加了7个间隙锁.

![image-20210415150338276](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415150338276.png)

##### 3.3.1.1.行锁的冲突关系

![image-20210415150411764](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415150411764.png)

##### 3.1.1.2.间隙锁的冲突的关系

跟间隙锁存在冲突关系的,是"往这个间隙中插入一个记录"这个操作,间隙锁之间不存在冲突..

间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 `select * from t for update; `要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。

但是间隙锁的引入容易导致死锁;

![image-20210415150641003](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415150641003.png)

#### 3.3.2.读提交模式

间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。

## 4.加锁规则

因为间隙锁是在可重复读隔离级别下才有效,所以如下说明默认都是可重复读隔离级别;

加锁规则如下:

1. 原则1:加锁的基本单位是next-key lock,next-key lock是前开后闭区间;
2. 原则2:查找过程中访问到的对象才会加锁;
3. 优化1:索引上的等值查询,给唯一索引加锁的时候,next-key lock退化成行锁;
4. 优化2:索引上的等值查询,向右遍历时且最后一个值不满足等值条件时,next-key lock退化成间隙锁;
5. 一个Bug:唯一索引上的范围查询会访问到不满足条件的第一个值为止;

### 4.1.案例一:等值查询间隙锁

~~~SQL
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
~~~

![image-20210415155723469](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415155723469.png)

1. 根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；
2. 同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。

### 4.2.案例二:非唯一索引等值锁

![image-20210415155953811](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415155953811.png)

1. 根据原则1,加锁单位是next-key lock,因此会给(0,5]加上next-key lock;
2. 因为c不是唯一索引,因此访问c=5这一条记录是不能马上停下来的,需要向右遍历,查到c=10才放弃,根据原则2,访问到的都要加锁,因此要给(5,10]加next-key;
3. 但是同时这个符合优化2:等值判断,向右遍历,最后一个值不满足c=5这个等值条件,因此退化成间隙锁(5,10);
4. 根据原则2,只有访问到的对象才会加锁,这个查询使用覆盖索引,并不需要访问主键索引,所以主键索引上没有加任何索引,sessionB的update可以执行;

在这个例子中,lock in share mode只锁覆盖索引,但是如果是for update时候,系统会认为接下来要更新数据,因此会顺带给主键索引上满足条件的行加上行锁;

上述例子说明,锁是加载索引上的;同时,如果要使用lock in share mode来给行加读锁避免数据被更新的话,就必须绕过覆盖索引优化,

### 4.3.案列三:主键索引范围锁

~~~mysql
mysql> select * from t where id=10 for update;
mysql> select * from t where id>=10 and id<11 for update;
~~~

## 5.如何临时提升MySQL性能

## 6.MySQL如何保证数据不丢?

### 6.1.binlog的写入机制

binlog的写入逻辑比较简单:事务执行过程中,先把日志写到binlog cache,事务提交的时候,再把binlog cache写到binlog文件中;一个事务的binlog是不能被拆开的,因此不论这个事务多大,也要确保一次性写入.这就涉及到了binlog cache的保存问题;系统给binlog cache分配了一片内存,每个线程一个,参数binlog_cache_size用于控制单个线程内binlog cache所占内存的大小.如果超过了这个参数规定的大小,就要暂存到磁盘;事务提交的时候,执行器把binlog cache里完整的事务写入到binlog中,并清空binlog cache.

![image-20210415164901272](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415164901272.png)

每个线程有自己的binlog cache,但是共用同一份binlog文件;

* 图中的write,指的就是把日志写入到文件系统的page cache,并没有把数据持久化到磁盘,所以速度比较快.
* 图中的fsync,才是将数据持久化到磁盘的操作.一般情况下,fsync才占磁盘的IOPS;

write和fsync的时机,是由参数sync_binlog控制的:

1. sync_binlog=0的时候,表示每次提交事务都只write,不fsync;
2. sync_binlog=1的时候,表示每次提交事务都会执行fsync;
3. sync_binlog=N(N>1)的时候,表示每次提交事务都write,但累计N个事务后才fsync;

因此,在出现IO瓶颈的场景里,将sync_binlog设置成一个比较大的值,可以提升性能.在实际的业务场景中,考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值.但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。

### 6.2.redo log的写入机制

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415171348206.png" alt="image-20210415171348206" style="zoom:50%;" />

redo log有三种状态分别是:

1. 存在redo log buffer中,物理上是在MySQL进程内存中;
2. 写到磁盘(write),但是没有持久化(fsync),物理上是在文件系统的page cache里面,也就是图中的黄色部分;
3. 持久化到磁盘,对应的是hard disk,也就是图中的绿色部分.

InnoDB提供了innodb_flush_log_at_trx_commit参数,它有三种可能取值;

1. 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;
2. 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；
3. 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

InnoDB有一个后台线程,每隔1s,就会把redo log buffer中的日志,调用write写到文件系统的page cache,然后调用fsync持久化磁盘;注意,事务执行中间过程的redo log也是直接写在redo log buffer中的,这些redo log也会被后台线程一起持久化到磁盘.也就是说,一个没有提交的事务的redo log,也是可能已经持久化到磁盘的;还有两种场景会让一个没有提交的事务的redo log写入到磁盘中;

1. 一种是,redo log buffer占用的空间即将达到innodb_log_buffer_size一半的时候,后台线程会主动写盘.由于这个事务并没有提交,所以这个写盘动作只是write,而没有调用fsync,也就是只留在了文件系统的page cache;
2. 另一种是,并行事务提交的时候,顺带将这个事务的redo log buffer持久化到磁盘.假设一个事务A执行到一半,已经写了一些redo log到buffer中,这时候有另外一个线程的事务B提交,如果innodb_flush_log_at_trx_commit设置的是1,那么按照这个参数的逻辑,事务B要把redo log buffer里的日志全部持久化到磁盘.这时候,就会带上事务A在redo log buffer里的日志一起持久化到磁盘;

如果把innodb_flush_log_at_trx_commit设置成1,那么redo log在prepare阶段就要持久化一次,因为有一个崩溃恢复逻辑是要依赖于prepare的redo log,再加上binlog来恢复的.

通常我们说MySQL的"双1"配置,指的就是sync_binlog和innodb_flush_log_at_trx_commit都设置成1.也就是说,一个事务完整提交前,需要等待两次刷盘,一次是redo log(prepare阶段),一次是binlog;

### 6.3.组提交(Group commit)机制

日志序列号(log sequence number,LSN).LSN是单调递增的,用来对应redo log的一个个写入点,每次写入长度为length的redo log,LSN的值就会加上length.LSN也会写到InnoDB的数据页中,来确保数据页不会被多次执行重复的redo log.

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210417103646966.png" alt="image-20210417103646966" style="zoom: 50%;" />



上图是三个并发事务在prepare阶段,都写完redo log buffer,持久化到磁盘的过程,对应的LSN分别是50,120,160;

1. trx1是第一个到达的,会被选为这组的leader;
2. 等trx1要开始写盘的时候,这个组里面已经有了三个事务,这时候LSN也变成了160;
3. trx1去写盘的时候,带的就是LSN=160,因此等trx1返回时,所有LSN小于等于160的redo log,都已经被持久化到磁盘;
4. 这时候trx2和trx3可以直接返回了;

在并发更新场景下,第一个事务写完redo log buffer以后,接下来这个fsync越晚调用,组员可能越多,节约IOPS的效果就越好.

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210417104302807.png" alt="image-20210417104302807" style="zoom:50%;" />

MySQL的两阶段提交做了优化如上图:第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。

如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。

* binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
* binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。

所以我们就可以知道WAL机制的好处:

* redo log 和binlog都是顺序写,磁盘的顺序写比随机写速度要快;
* 组提交机制,可以大幅度降低磁盘的IOPS消耗;

### 6.4.IO性能瓶颈,如何提升性能?

1. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
2. 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
3. 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。

## 7.MySQL如何保证主备一致?

### 7.1.MySQL的主备的基本原理

![image-20210415181117007](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415181117007.png)

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210415181311909.png" alt="image-20210415181311909" style="zoom: 67%;" />

我们看看节点A到B这条线的内部流程是怎么样的.备库B跟主库A之间维持了一个长连接.主库A内部有一个线程,专门用于服务备库B的这个长连接.一个事务日志同步的完整过程是这样的:

1. 在备库B上通过change master命令,设置主库A的IP,端口,用户名,密码,以及要从哪个位置开始请求binlog,这个位置包含文件名和日志偏移量;
2. 在备库B上执行start slave命令,这时候备库会启动两个线程,就是图中的io_thread和sql_thread.其中io_thread负责与主库建立连接.
3. 主库A效验完用户名,密码后,开始按照备库B传过来的位置,从本地读取binlog,发给B;
4. 备库B拿到binlog后,写到本地文件,称为中转日志(relay log);
5. sql_thread 读取中转日志,解析出日志里的命令,并执行;

### 7.2.binlog的三种格式对比

binlog有三种格式,一种是statement,一种是row,一种叫做mixed;

#### 7.2.1.statement

当binlog_format=statement时,binlog里面记录的就是SQL语句的原文.可以使用`show binlog events in 'xxxx'`命令看binlog重的内容;

![image-20210416093614778](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416093614778.png)

第一行:忽略;

第二行:BEGIN,跟第四行的commit对应,表示中间是一个事务;

第三行:在真实执行的delete命令之前,还有一个'use test'命令,这条命令不是我们主动执行的,而是MySQL根据当前要操作的表所在的数据库,自行添加的,这样做可以保证日志到备库执行的时候,不论当前的工作线程在哪个库里,都能够正确的更新到正确的库和正确的表;

第四行:COMMIT,可以看到里面有xid=61,XID是用来联系bin log和redo log的。比如redo log里面有一个事务是prepare状态，但是不知道是不是commit状态，那就可以用XID去bin log里面查询该事务到底有没有提交。有提交则是commit状态，若没有提交则回滚该事务。

由于statement格式下,记录到binlog里的是语句原文,因此可能出现这样的一种情况:在主库执行这条语句的时候,用的是索引a,而在备库执行SQL的时候语句的时候,却使用了索引t_modified.因此,MySQL认为这样是有风险的;

#### 7.2.2.row

![image-20210416094614835](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416094614835.png)

1. Table_map event,用于说明接下来要操作的表示test库的表t;
2. Delete_rows event,用于定义删除行为;

其实通过上图是看不到详细信息的,需要借助mysqlbinlog工具,用mysqlbinlog查看binlog中的内容.

```sql
mysqlbinlog  -vv data/master.000001 --start-position=8900;
```

![image-20210416100300991](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416100300991.png)

1. server id 1,表示这个事务是在server_id = 1这个库上执行的;
2. Table_map event显示了接下来要打开的表,map到数字226,因为只操作了一张表,如果要操作多张表,每个表都有一个对应的Table_map event,都会map到一个单独的数值,用于区分对不同表的操作;
3. 在`mysqlbinlog`的命令中,使用`-vv`参数是为了把内容都解析出来,所以从结果里面可以看到各个字段的值(比如:@1=4,@2=4);
4. binlog_row_image的默认配置是FULL,因此Delete_event里面包含了删掉的行的所有字段的值,如果把binlog_row_image设置的是MINIMAL,则会记录必要信息.
5. Xid event,表示事务被正确提交了;

当binlog_format使用row格式的时候,binlog里面记录了真实删除行的组件id,这样binlog传到备库去的时候,就肯定会删除id=4的行,不会有主备删除不同行的问题.

#### 7.2.3.Mixed

为什么会有mixed格式的binlog

* 因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。
* 但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。
* 所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。

### 7.3.循环复制问题

生产上使用比较多的是双M结构,双M结构和M-S结构,其实区别就是多了一条线,即节点之间互为主备关系,这样在切换的时候不用再修改主备关系了.

![image-20210416103830566](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416103830566.png)

1. 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；
2. 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；
3. 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。

按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：

1. 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；
2. 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；
3. 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。

## 8.MySQL如何保证高可用?

### 8.1.主备延迟

主备切换可能是一个主动运维动作,比如软件升级,主库所在机器按计划下线等,也可能是被动操作,比如主库所在机器掉电.

首先要说明的概念是:同步延迟,与数据同步有关的时间点主要包括以下三个:

1. 主库A执行完成一个事务,写入binlog,该时刻记成T1;
2. 之后传给备库B,备库B接收完这个binlog的时刻记成T2;
3. 备库B执行完成这个事务,这个时刻记为T3;

所谓主备延迟,就是同一个事务,在备库执行完成的时间和主库执行完成的时间之间的差值,也就是T3-T1;可以在备库上执行`show slave status`命令,它的返回结果里面会显示second_behind_master,用于表示当前备库延迟了多少秒;

second_behind_master的计算方法是:

1. 每个事务的binlog里面都有一个时间字段,用于记录主库上写入的时间;
2. 备库取出当前正在执行的事务时间字段的值,计算与当前系统时间的差值,得到secon_behind_master;精度为秒;

在网络正常的时候,日志从主库传给备库所需要的时间是很短的,即T2-T1的值是非常小的.网络正常的情况下,主备按此的主要来源是备库接收完binlog和执行完这个事务之间的时间差.所以,主备延迟最直接的表现是:备库消费中转日志(relay log)的速度,比主库生产binlog的速度要慢.

### 8.2.主备延迟的原因

更新请求对 IOPS 的压力，在主库和备库上是无差别的。所以，做这种部署时，一般都会将备库设置为“非双 1”的模式。但实际上，更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了.

如果主备库选用相同规格的机器,并且做对称部署,是现在比较常见的情况.但是备库有可能压力还是很大,一般的想法是,主库既然提供了写能力,那么备库可以提供一些读能力.有可能大量的读放到了从库上.

### 8.3.主备切换策略

#### 8.3.1.可靠性优先策略

![image-20210416135841108](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416135841108.png)

1. 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；
2. 把主库 A 改成只读状态，即把 readonly 设置为 true；
3. 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；
4. 把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
5. 把业务请求切到备库 B。这个切换流程，一般是由专门的 HA 系统来完成的，我们暂时称之为可靠性优先流程。

#### 8.3.2.可用性优先策略

如果我们直接把连接切到备库B,并且让备库B可以读写,那么系统几乎就没有不可用时间了.这个切换流程,叫做可用性有限流程,切换流程的代价,就是可能出现数据不一致的情况.

下图是可用性优先策略,并且`binlog_format=mixed`导致数据不一致.

![image-20210416140351685](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416140351685.png)

如果使用的是可用性优先策略,并且`binlog_format=row`因为row格式在记录binlog时,会记录新插入的行的所有字段的值,所以最后只会有一行不一致,而且两边主备同步的应用线程会报错`duplicate key error`并停止.

![image-20210416140742936](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416140742936.png)

在满足数据可靠性的前提下,MySQL高可用系统的可用性,是依赖于主备延迟的.延迟时间越小,在主库故障的时候,服务恢复需要的时间就越短,可用性就越高.

### 8.4.备库并行复制能力(?)

如果备库执行日志的速度持续低于主库生成日志的速度,那这个延迟就有可能成了小时级别.

![image-20210416142629940](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416142629940.png)

在5.6版本之前,MySQL支持单线程复制,由此在主库并发高,TPS高时就会出现严重的主备延迟问题.

![image-20210416143129048](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416143129048.png)

所有的多线程复制机制,都是要把图中的只有一个线程sql_thread,拆成多个线程.上图中的coordinator就是原来的sql_thread,不过现在它不再直接更新数据了,只负责读取中转日志和分发事务.真正更新日志的,变成了work线程,而worker线程的个数,就是由参数slave_parallel_workers决定的.

事务能不能按照轮询的方式分发给各个worker,也就是第一个事务分给worker_1,第二个分给worker_2?不行,因为事务分发给worker之后,不同的worker就独立执行了.但是由于CPU的调度策略,很可能第二个事务最终比第一个事务先执行.而如果这时候刚好这两个事务更新的是同一行,也就意味着,同一行上的两个事务,在主库和备库上的执行顺序想法,会导致主备不一致的问题.

同一个事务的多个更新语句,能不能分给不同的worker来执行?不行,一个事务更新了表t1和表t2中的各一行,如果这两条更新的语句被分到不同的worker的话,虽然最终的结果是主备一致的,但如果表t1执行完成瞬间,备库上有一个查询,就会看到这个事务更新了一半的结果,破坏了事务逻辑的隔离性.

coordinator在分发的时候,需要满足两个基本要求:

1. 不能造成更新覆盖,这就要求更新同一行的两个事务,必须被分发到同一个worker中;
2. 同一个事务不能被拆开,必须放到同一个worker中.

### 8.5.主库出问题的从库策略

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416152138082.png" alt="image-20210416152138082" style="zoom:50%;" />

A和A'互为主备,从库B,C,D指向的是主库A,一主多从的设置,一般用于读写分离,主库负责所有的写入和一部分读,其他的读请求则从从库分担.

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416152436688.png" alt="image-20210416152436688" style="zoom:50%;" />

一主多从结构在切换完成后,A'会成为新的主库,从库B,C,D也要改接到A'.正是由于多了从库B,C,D重新指向的这个过程,所以主备切换的复杂性也相应增加了.

#### 8.5.1.基于位点的主备切换

当把节点B设置成节点A'的从库的时候,需要执行一条change master命令:

~~~shell
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
MASTER_LOG_FILE=$master_log_name 
MASTER_LOG_POS=$master_log_pos  
~~~

最后两个参数MASTER_LOG_FILE和MASTER_LOG_POS表示,要从主库的master_log_name文件的master_log_Pos这个位置的日志继续同步,而这个位置就是我们所说的同步位点,也就是主库对应的文件名和日志偏移量;

原来节点B是A的从库,本地记录的也是A的位点.但是相同的日志,A的位点和A'的位点是不同的.因此,从库B要切换的时候,就要先找同步位点.在切换过程中不能丢数据,找位点的时候,总是要找一个"稍微往前"的,然后再通过判断跳过那些在从库B上已经执行过的事务.

1. 等待新主库 A’把中转日志（relay log）全部同步完成；
2. 在 A’上执行 show master status 命令，得到当前 A’上最新的 File 和 Position；
3. 取原主库 A 故障的时刻 T；
4. 用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点。`mysqlbinlog File --stop-datetime=T --start-datetime=T`;
5. 得到在T时刻写入新的binlog的位置.然后就可以把这个值作为`$master_log_pos`,用在节点B的`change master`命令你.

但是假设在T这个时刻,主库A已经执行完一个Insert语句插入了一行数据R,并且已经将binlog传给了A'和B,然后在传完的瞬间主库A的主机就掉电了.情况如下:

1. 在从库 B 上，由于同步了 binlog， R 这一行已经存在；
2. 在新主库 A’上， R 这一行也已经存在，日志是写在 xxx 这个位置之后的；
3. 我们在从库 B 上执行 change master 命令，指向 A’的 File 文件的 xxx 位置，就会把插入 R 这一行数据的 binlog 又同步到从库 B 去执行。

这时候,从库B的同步线程就会报告`Duplicate entry ‘id_of_R’ for key ‘PRIMARY’`错误,提示出现了主键冲突,然后停止同步.常用做法如下:

* 主动跳过一个事务,跳过命令的写法是:`set global sql_slave_skip_counter=1;start slave;`因为在切换过程中,可能会不重复执行一个事务,所以我们需要在从库B刚开始街道新主库A'时,持续观察,每次碰到这些错误就停下来,执行一次跳过命令;

* 通过设置`slave_skip_errors`参数,直接设置跳过指定的错误;在执行主备切换时候有两类错误经常遇到:

  * 1062错误是插入数据时唯一键冲突;
  * 1032错误是删除数据时找不到行;

  因此我们可以把`slave_skip_errors`设置为"1032,1062",这样中间碰到这两个错误时就直接跳过了.这里需要注意的是,这种直接跳过指定错误的方法,针对的是主备切换时,由于找不到精确的同步位点,所以只能采用这种方法来创建从库和新主库的准备关系.等到准备减的同步关系建立完成,我们还需要把这个参数设置为空.

#### 8.5.2.基于GTID的主备切换

##### 8.5.2.1.GTID

MySQL5.6版本引入了GTID.GTID的全称是Global Transaction Identifier,也就是全局事务ID,是一个事务在提交的时候生成的,是这个事务的唯一标识,格式是:`GTID=server_uuid:gno`;

* server_uuid是一个实例第一次启动时自动生成的,是一个全局唯一的值;
* gno是一个整数,初始值是1,每次提交事务的时候分配给这个事务,并加1;
* 在MySQL的官方文档中,GTID格式是`GTID=source_id:transaction_id`;
* GTID模式的启动子需要在启动一个MySQL实例的时候,加上参数`gtid=mode=on`和`enforce_gtid_consistency=on`就可以了;

GTID模式下,每个事务都会跟一个GTID意义对应,GTID有两种生成方式,使用哪种取决于session变量`gtid_next`的值;

1. 如果`gtid_next=automatic`,代表使用默认值,这时,MySQL就会把server_uuid:gno分配给这个事务;
   1. 记录binlog的时候,先记录一行`SET @@SESSION.GTID_NEXT='server_uuid:gno'`;
   2. 把这个GTID加入本实例的GTID集合;
2. 如果`gtid_next`是一个指定的GTID的值,比如通过`set gtid_next='current_gtid'`指定为current_gtid,就会有两种可能:
   1. 如果current_gtid已经存在于实例的GTID集合中,接下来执行的这个事务会直接被系统忽略;
   2. 如果current_gtid没有存在于实例的GTID集合中,就将这个current_gtid分配给接下来要执行的事务,也就是说系统不需要给这个事务生成新的GTID,因此gno也不用加1;
   3. 一个current_gtid只能给一个事务使用,这个事务提交后,如果要执行下一个事务,就要执行set命令,把gtid_next设置成另外一个gtid或automatic;

##### 8.5.2.2.GTID的主备切换实现

在GTID模式下,备库B要设置为新主库A'的从库的语法如下:

~~~shell
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
master_auto_position=1 
~~~

master_auto_position=1就表示这个主备关系使用的是GTID协议.

实例 A’的 GTID 集合记为 set_a，实例 B 的 GTID 集合记为 set_b.在实例B上执行start slave命令,取binlog的逻辑是这样的:

1. 实例 B 指定主库 A’，基于主备协议建立连接。
2. 实例 B 把 set_b 发给主库 A’。
3. 实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。
   1. 如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；
   2. 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。

## 9.读写分离的问题

### 9.1.读写分离的基本结构

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416154127514.png" alt="image-20210416154127514" style="zoom:50%;" />

读写分离的主要目标就是分摊主库的压力.图1中的结构是客户端(client)主动做负载均衡,这种模式下一般会把数据库的连接信息放在客户端连接层.也就是说,由客户端来选择后端数据库进行查询.

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210416154417658.png" alt="image-20210416154417658" style="zoom:50%;" />

还有一种架构是,在MySQL喝客户端之间有一个中间代理层proxy,客户端只连接proxy,由proxy根据请求类型和上下文决定请求的分发路径.

这两种架构各有优劣,目前的趋势是往带proxy的架构方向发展.但是不论使用哪种架构,都会由于主从可能存在延迟,客户端执行完一个更新事务后马上发起查询,如果查询选择的是从库的话,就有可能读到刚刚的事务更新之前的状态.这种在从库上会读到系的一个过期状态的现象,称之为过期读.

过期读的方案汇总如下:

* 强制走主库方案;
* sleep方案;
* 判断主库无延迟方案;
* 配合semi-sync方案;
* 等主库位点方案;
* 等GTID方案;

### 9.2.强制走主库方案

强制走主库方案就是将查询请求做分类,对于必须拿到最新结果的请求,强制将其发到主库上.对于可以读到旧数据的请求,才将其发到从库上.

### 9.3.Sleep方案

主库更新后,读从库之前先sleep一下,具体方案是:类似执行一条`select sleep(1)`命令;

### 9.4.判断主备无延迟方案

如下的判断都不是准确的,因为从binlog在主备之间状态的分析中,看出还有一部分日志,处于客户端已经收到提交确认,而备库还没收到日志的状态.

![image-20210417145900080](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210417145900080.png)

#### 9.4.1.方案一:查询前,判断`seconds_behind_master`

第一种确保主备无延迟的方法是:每次从库执行查询请求前,先判断`seconds_behind_master`是否已经等于0,如果还不等于0,那就必须等到这个参数变为0才能执行查询.因为`seconds_behind_master`的单位是秒,所以不够精确

#### 9.4.2.方案二:对比位点

![image-20210417145001516](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210417145001516.png)

`show slave status`得到上图信息:

* Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；
* Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。
* 如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。

#### 9.4.3.方案三:对比GTID集合确保主备无延迟

* Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。
* Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；
* Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。
* 如果这两个集合相同，也表示备库接收到的日志都已经同步完成。

#### 9.4.4.方案四:配合semi-sync

引入半同步机制,也是就是semi-sync replication.

1. 事务提交的时候，主库把 binlog 发给从库；
2. 从库收到 binlog 以后，发回给主库一个 ack，表示收到了；
3. 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。

但是semi-sync还有个两个问题:

1. semi-sync只对一主一备的场景是成立的,在一主多从的场景中,主库只要等到一个从库的ack,就开始给客户端返回确认.就会出现有可能出现过期读的情况;
2. 如果是在业务更新的高峰期,主库的位点或者GTID集合更新很快,那么上面两个位点等值判断就会一直不成立,很可能出现从库迟迟无法响应查询请求的情况.

#### 9.4.5.方案五:等主库位点

在从库执行`select master_pos_wait(file, pos[, timeout]);`

这条命令的逻辑如下:

1. 它是在从库执行的；
2. 参数 file 和 pos 指的是主库上的文件名和位置；
3. timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。

这个命令正常返回的结果是一个正整数M,表示从命令开始执行,到应用完file和pos表的binlog位置,执行了多少事务;当然也会返回一些其他结果:

1. 如果执行期间，备库同步线程发生异常，则返回 NULL；
2. 如果等待超过 N 秒，就返回 -1；
3. 如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0。

对于在主库中执行一个事务trx1,再执行一个查询请求的逻辑,要保证能够查到正确的数据,可以使用:

1. rx1 事务更新完成后，马上执行 show master status 得到当前主库执行到的 File 和 Position；
2. 选定一个从库执行查询语句；
3. 在从库上执行 select master_pos_wait(File, Position, 1)；
4. 如果返回值是 >=0 的正整数，则在这个从库执行查询语句；
5. 否则，到主库执行查询语句。

#### 9.4.6.方案六:GTID方案

在从库执行一条` select wait_for_executed_gtid_set(gtid_set, 1);`

这条命令的逻辑是:

1. 等待,直到这个库执行的事务中包含传入的gtid_set返回0;
2. 超时返回1;

方案流程:

1. trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；
2. 选定一个从库执行查询语句；
3. 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；
4. 如果返回值是 0，则在这个从库执行查询语句；
5. 否则，到主库执行查询语句。

### 9.5.如何判断数据库是否出问题?

主备切换有两种场景,一种是主动切换,一种是被动切换,其中被动切换,往往是因为主库出问题了,由HA系统发起的.

#### 9.5.1.select 1判断

实际上,select 1成功返回,只能说明这个库的进程还在,并不能说明主库没问题.

~~~SQL

set global innodb_thread_concurrency=3;

CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

 insert into t values(1,1)
~~~

![image-20210417163042314](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210417163042314.png)

设置innodb_thread_concurrency参数的目的是,控制InnoDB的并发线程上限.也就是说,一旦并发线程数达到这个值,InnoDB在接收到新请求的时候,就会进入等待状态,直到有线程退出.在InnoDB中,innodb_thread_concurrency这个参数的默认值是0,表示不限制并发线程数量.但是,不限制并发线程数肯定不行,因为,一个机器的CPU核数有限,线程全冲进来,上下文切换的成本就会太高.

##### 9.5.1.1.并发连接和并发查询

并发连接和并发查询，并不是同一个概念。你在 show processlist 的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。这也是为什么我们需要设置 `innodb_thread_concurrency` 参数的原因。

#### 9.5.2.查表判断

为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问 InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行.

~~~SQL
mysql> select * from mysql.health_check; 
~~~

使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况.空间满了以后，这种方法又会变得不好使。我们知道，更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的.

#### 9.5.3.更新判断

????

